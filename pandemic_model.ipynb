{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STATIC V1: SLF Pandemic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "python37_geo",
      "language": "python",
      "name": "python37_geo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_C5c-iszeXFF"
      },
      "source": [
        "# **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fWmw4GRrWDA9",
        "colab": {}
      },
      "source": [
        "#import necessary packages\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from scipy.spatial import distance\n",
        "import math\n",
        "import geopandas\n",
        "from shapely.geometry.polygon import Polygon\n",
        "from shapely.geometry.multipolygon import MultiPolygon\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## Packages for use in CoLab\n",
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "536MsaaOeccI"
      },
      "source": [
        "# **Directory Path(s)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-NH4e9NRjYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'G:/Shared drives/APHIS  Projects/Pandemic/Data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RUh53I7KefsH"
      },
      "source": [
        "# **Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LVDFV87sdru9",
        "colab": {}
      },
      "source": [
        "def climate_similarity(origin_climates, destination_climates):\n",
        "    \"\"\"\n",
        "    Returns the climate similarity between origin (i) and destion (j) by\n",
        "    simply checking whether or not the climate type is present in both the\n",
        "    origin (i) and destination (j) and summing the total area in the\n",
        "    destination (j) that is also in the origin (i).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    origin_climates : array (float)\n",
        "        An array with percent area for each of the Koppen climate zones for the\n",
        "        origin (i)\n",
        "    destination_climates : array (float)\n",
        "        An array with percent area for each of the Koppen climate zones for the\n",
        "        destination (j)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    similarity : float\n",
        "        What percentage of the total area of the origin country\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    similarity = 0.00\n",
        "    for clim in range(len(origin_climates)):\n",
        "        if origin_climates[clim] > 0 and destination_climates[clim] > 0:\n",
        "            similarity += destination_climates[clim]\n",
        "\n",
        "    return similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Mu6KaRlyg_P",
        "colab": {}
      },
      "source": [
        "def distance_between(shapefile):\n",
        "    \"\"\"\n",
        "    Returns a n x n numpy array with the the distance from each element in a\n",
        "    shapefile to all other elements in that shapefile.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    shapefile : geodataframe\n",
        "        A geopandas dataframe of countries with crs(epsg = 4326)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    distance : numpy array\n",
        "        An n x n numpy array of distances from each location to every other\n",
        "        location in kilometer\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    centroids = shapefile.centroid.geometry\n",
        "    centroids = centroids.to_crs(epsg=3395)\n",
        "    shapefile[\"centroid_lon\"] = centroids.x\n",
        "    shapefile[\"centroid_lat\"] = centroids.y\n",
        "    centroids_array = shapefile.loc[:, [\"centroid_lon\", \"centroid_lat\"]].values\n",
        "    distance_array = distance.cdist(centroids_array, centroids_array, \"euclidean\")\n",
        "    distance_array = distance_array/1000\n",
        "    \n",
        "    return distance_array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YpkOJc5NjMHc",
        "colab": {}
      },
      "source": [
        "def probability_of_entry(\n",
        "    rho_i, rho_j, zeta_it, lamda_c, T_ijct, sigma_T, mu, d_ij, chi_it\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of entry given trade volume, distance, and\n",
        "    capacity between two locations. We are thinking of locations as ports or\n",
        "    countries in which international trade happens.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rho_i : float\n",
        "        The phytosanitary capacity of origin (i)\n",
        "    rho_j : float\n",
        "        The phytosanitary capacity of destination (j)\n",
        "    zeta_it : bool\n",
        "        Species presence in origin (i) at time (t)\n",
        "    lamda_c : float\n",
        "        The commodity importance [0,1] of commodity (c) in transporting the\n",
        "        pest or pathogen\n",
        "    T_ijct : float\n",
        "        The trade volume between origin (i) and destination (j) for commodity\n",
        "        (c) at time (t) in metric tons\n",
        "    mu : float\n",
        "        The mortality rate of the pest or pathogen during transport\n",
        "    d_ij : int\n",
        "        the distance between origin (i) and destination (j)\n",
        "    chi_it : bool\n",
        "        The seasonality of the pest or pathogen in its ability to be in a\n",
        "        shipment\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_entry : float\n",
        "        The probability of a pest to enter the origin location\n",
        "\n",
        "    See Also\n",
        "    probability_of_establishment : Calculates the probability of establishment\n",
        "    probability_of_introduction : Calculates the probability of introduction\n",
        "        from the probability_of_establishment and probability_of_entry\n",
        "    \"\"\"\n",
        "\n",
        "    return (\n",
        "        (1 - rho_i)\n",
        "        * (1 - rho_j)\n",
        "        * zeta_it\n",
        "        * (1 - math.exp((-1) * lamda_c * (T_ijct / sigma_T)))\n",
        "        * math.exp((-1) * mu * d_ij)\n",
        "        * chi_it\n",
        "    )\n",
        "\n",
        "\n",
        "def probability_of_establishment(\n",
        "    alpha,\n",
        "    beta,\n",
        "    delta_kappa_ijt,\n",
        "    sigma_kappa,\n",
        "    h_jt,\n",
        "    sigma_h,\n",
        "    epsilon_jt,\n",
        "    sigma_epsilon,\n",
        "    phi,\n",
        "    sigma_phi,\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of establishment between origin (i) and destination\n",
        "    (j) given climate similarity between (i and j), host area in (j),\n",
        "    ecological distrubance in (j), and degree of polyphagy of the pest species.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha : float\n",
        "        A parameter that allows the equation to be adapated to various discrete\n",
        "        time steps\n",
        "    beta : float\n",
        "        A parameter that allows the equation to be adapted to various discrete\n",
        "        time steps\n",
        "    delta_kappa_ijt :float\n",
        "        The climate dissimilarity between the origin (i) and destination (j)\n",
        "        at time (t)\n",
        "    sigma_kappa : float\n",
        "        The climate dissimilarity normalizing constant\n",
        "    h_jt : float\n",
        "        The percent of area in the destination (j) that has suitable host for\n",
        "        the pest\n",
        "    sigma_h : float\n",
        "        The host normalizing constant\n",
        "    epsilon_jt : float\n",
        "        The ecological disturbance index of destination (j) at time (t)\n",
        "    sigma_epsilon : float\n",
        "        The ecological disturbance normalizing constant\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_phi : int\n",
        "        The degree of polyphagy normalizing constant\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_establishment : float\n",
        "        The probability of a pest to establish in the origin location\n",
        "\n",
        "    See Also\n",
        "    probability_of_entry : Calculates the probability of entry\n",
        "    probability_of_introduction : Calculates the probability of introduction\n",
        "        from the probability_of_establishment and probability_of_entry\n",
        "    \"\"\"\n",
        "\n",
        "    return alpha * math.exp(\n",
        "        (-1)\n",
        "        * beta\n",
        "        * (\n",
        "            ((1 - delta_kappa_ijt) / sigma_kappa) ** 2\n",
        "            + ((1 - h_jt) / sigma_h) ** 2\n",
        "            + ((1 - epsilon_jt) / sigma_epsilon) ** 2\n",
        "            + (phi / sigma_phi) ** (-2)\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def probability_of_introduction(\n",
        "    probability_of_entry_ijct, probability_of_establishment_ijt\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of introduction given a vector of\n",
        "    probability_of_entry between origin (i) and destination (j) at time t\n",
        "    with c commodities and a probability_of_establishment between origin (i)\n",
        "    and destination (j)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    probability_of_entry_ijct : float\n",
        "        The probability of a pest entering destination (j) from origin (i) on\n",
        "        commodity (c) at time (t)\n",
        "    probability_of_establishment_ijt : float\n",
        "        The probability of a pest establishing in destination (j) coming from\n",
        "        origin (i) at time (t)\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_introduction : float\n",
        "        The probability of a pest being introduced in the origin (i) location\n",
        "        from destination j\n",
        "\n",
        "    See Also\n",
        "    probability_of_entry : Calculates the probability of entry\n",
        "    probability_of_establishment : Calculates the probability of establishment\n",
        "    \"\"\"\n",
        "\n",
        "    return probability_of_entry_ijct * probability_of_establishment_ijt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wu6__Q8-jeqf",
        "colab": {}
      },
      "source": [
        "def pandemic(\n",
        "    trade,\n",
        "    distances,\n",
        "    locations,\n",
        "    alpha,\n",
        "    beta,\n",
        "    mu,\n",
        "    lamda_c,\n",
        "    phi,\n",
        "    sigma_epsilon,\n",
        "    sigma_h,\n",
        "    sigma_kappa,\n",
        "    sigma_phi,\n",
        "    sigma_T,\n",
        "    time_step\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of establishment, probability of entry, and\n",
        "    probability of introduction as an n x n matrices between every origin (i)\n",
        "    and destination (j) and update species presence and the combined\n",
        "    probability of presence for each origin (i) given climate similarity\n",
        "    between (i and j), host area in (j), ecological distrubance in (j), degree\n",
        "    of polyphagy of the pest species, trade volumes, distance, and\n",
        "    phytosanitary capacity.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    locations : data_frame\n",
        "        data frame of countries, species presence, phytosanitry capacity,\n",
        "        koppen climate classifications % of total area for each class.\n",
        "    trade : numpy.array\n",
        "        list (c) of n x n x t matrices where c is the # of commoditites,\n",
        "        n is the number of locations, and t is # of time steps\n",
        "    distances : numpy.array\n",
        "        n x n matrix of distances from one location to another where n is\n",
        "        number of locations.\n",
        "    alpha : float\n",
        "        A parameter that allows the equation to be adapated to various discrete\n",
        "        time steps\n",
        "    beta : float\n",
        "        A parameter that allows the equation to be adapted to various discrete\n",
        "        time steps\n",
        "    mu : float\n",
        "        The mortality rate of the pest or pathogen during transport\n",
        "    lamda_c : float\n",
        "        The commodity importance [0,1] of commodity (c) in transporting the\n",
        "        pest or pathogen\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_kappa : float\n",
        "        The climate dissimilarity normalizing constant\n",
        "    sigma_h : float\n",
        "        The host normalizing constant\n",
        "    sigma_epsilon : float\n",
        "        The ecological disturbance normalizing constant\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_phi : int\n",
        "        The degree of polyphagy normalizing constant\n",
        "    sigma_T : int\n",
        "        The trade volume normalizing constant\n",
        "    time_step: str\n",
        "      The year-month combination of the time step. \n",
        "    random_seed : int (optional)\n",
        "        The number to use for initializing random values. If not provided, a new\n",
        "        value will be used for every simulation and results may differ for the\n",
        "        same input data and function parameters. If provided, the results of a\n",
        "        simulation can be reproduced.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_establishment : float\n",
        "        The probability of a pest to establish in the origin location\n",
        "\n",
        "    See Also\n",
        "    probability_of_entry : Calculates the probability of entry\n",
        "    probability_of_introduction : Calculates the probability of introduction\n",
        "        from the probability_of_establishment and probability_of_entry\n",
        "    \"\"\"\n",
        "\n",
        "    entry_probabilities = np.empty_like(trade, dtype=float)\n",
        "    establishment_probabilities = np.empty_like(trade, dtype=float)\n",
        "    introduction_probabilities = np.empty_like(trade, dtype=float)\n",
        "    \n",
        "    introduction_country = np.empty_like(trade, dtype=float)\n",
        "    locations[\"Probability of introduction\"] = np.empty(len(locations))\n",
        "    origin_destination = pd.DataFrame(columns=['Origin', 'Destination'])\n",
        "\n",
        "    \n",
        "    for j in range(len(locations)):\n",
        "        destination = locations.iloc[j, :]\n",
        "        combined_probability_no_introduction = 1\n",
        "    \n",
        "        # check that Phytosanitary capacity data is available if not set\n",
        "        # the value to 0 to remove this aspect of the equation\n",
        "        if \"Phytosanitary Capacity\" in destination:\n",
        "            rho_j = destination[\"Phytosanitary Capacity\"]\n",
        "        else:\n",
        "            rho_j = 0\n",
        "\n",
        "        for i in range(len(locations)):\n",
        "            origin = locations.iloc[i, :]\n",
        "            \n",
        "            # check that Phytosanitary capacity data is available if not\n",
        "            # set value to 0 to remove this aspect of the equation\n",
        "            if \"Phytosanitary Capacity\" in origin:\n",
        "                rho_i = origin[\"Phytosanitary Capacity\"] \n",
        "            else:\n",
        "                rho_i = 0\n",
        "\n",
        "\n",
        "            T_ijct = trade[j, i]\n",
        "            d_ij = distances[j, i]\n",
        "            \n",
        "            ## Need to generalize -- this is for SLF; add column for seasonality flag\n",
        "            #Northern Hemisphere & Fall/Winter Months\n",
        "            if origin['centroid_lat'] >= 0 and time_step[-2:] in ['09', '10', '11', '12', '01', '02', '03', '04']:\n",
        "                chi_it = 1\n",
        "            #Southern Hemisphere & Fall/Winter Months\n",
        "            elif origin['centroid_lat'] < 0 and time_step[-2:] in ['04', '05', '06', '07', '08', '09', '10']:\n",
        "                chi_it = 1\n",
        "            else:\n",
        "                chi_it = 0\n",
        "                \n",
        "            h_jt = destination[\"Host Percent Area\"]\n",
        "            \n",
        "            if origin[\"Presence\"] and h_jt > 0:\n",
        "                zeta_it = int(origin[\"Presence\"])\n",
        "\n",
        "                origin_climates = origin.loc[['Af', 'Am',\t'Aw',\t'BWh', 'BWk', \n",
        "                                              'BSh', 'BSk', 'Csa',\t'Csb', \n",
        "                                              'Csc', 'Cwa', 'Cwb', 'Cwc', \n",
        "                                              'Cfa',\t'Cfb', 'Cfc',\t'Dsa', \n",
        "                                              'Dsb',\t'Dsc', 'Dsd',\t'Dwa', \n",
        "                                              'Dwb',\t'Dwc', 'Dwd',\t'Dfa', \n",
        "                                              'Dfb',\t'Dfc', 'Dfd',\t'ET', 'EF']]\n",
        "\n",
        "                destination_climates = destination.loc[['Af', 'Am',\t'Aw',\t\n",
        "                                                        'BWh', 'BWk', 'BSh',\n",
        "                                                        'BSk', 'Csa',\t'Csb',\n",
        "                                                        'Csc', 'Cwa', 'Cwb',\n",
        "                                                        'Cwc', 'Cfa',\t'Cfb',\n",
        "                                                        'Cfc',\t'Dsa', 'Dsb',\n",
        "                                                        'Dsc', 'Dsd',\t'Dwa', \n",
        "                                                        'Dwb',\t'Dwc', 'Dwd',\n",
        "                                                        'Dfa', 'Dfb',\t'Dfc',\n",
        "                                                        'Dfd',\t'ET', 'EF']]\n",
        "                \n",
        "                delta_kappa_ijt = climate_similarity(origin_climates, destination_climates)\n",
        "\n",
        "                if \"Ecological Disturbance\" in origin:\n",
        "                    epsilon_jt = origin[\"Ecological Disturbance\"]\n",
        "                else:\n",
        "                    epsilon_jt = 0\n",
        "\n",
        "                \n",
        "                probability_of_entry_ijct = probability_of_entry(\n",
        "                    rho_i, rho_j, zeta_it, lamda_c, T_ijct, sigma_T, mu, d_ij, chi_it\n",
        "                )\n",
        "                \n",
        "                probability_of_establishment_ijt = probability_of_establishment(\n",
        "                    alpha,\n",
        "                    beta,\n",
        "                    delta_kappa_ijt,\n",
        "                    sigma_kappa,\n",
        "                    h_jt,\n",
        "                    sigma_h,\n",
        "                    epsilon_jt,\n",
        "                    sigma_epsilon,\n",
        "                    phi,\n",
        "                    sigma_phi,\n",
        "                )\n",
        "            \n",
        "            else:\n",
        "                zeta_it = 0\n",
        "                probability_of_entry_ijct = 0.0\n",
        "                probability_of_establishment_ijt = 0.0\n",
        "\n",
        "            probability_of_introduction_ijtc = probability_of_introduction(\n",
        "                probability_of_entry_ijct, probability_of_establishment_ijt\n",
        "            )\n",
        "            \n",
        "            entry_probabilities[j, i] = probability_of_entry_ijct\n",
        "            establishment_probabilities[j, i] = probability_of_establishment_ijt\n",
        "            introduction_probabilities[j, i] = probability_of_introduction_ijtc\n",
        "            \n",
        "            # decide if an introduction happens\n",
        "            introduced = np.random.binomial(1, probability_of_introduction_ijtc)\n",
        "            combined_probability_no_introduction = combined_probability_no_introduction * (1 - probability_of_introduction_ijtc)\n",
        "            \n",
        "            if bool(introduced):\n",
        "                introduction_country[j, i] = bool(introduced)\n",
        "                locations.iloc[j, locations.columns.get_loc(\"Presence\")] = bool(introduced)\n",
        "                print('\\t', origin['NAME'], '-->', destination['NAME'])\n",
        "                \n",
        "                if origin_destination.empty:\n",
        "                    origin_destination = pd.DataFrame([[origin['NAME'], \n",
        "                                                        destination['NAME']]], \n",
        "                                                      columns=['Origin', 'Destination'])\n",
        "                else:\n",
        "                    origin_destination = origin_destination.append(pd.DataFrame([[origin['NAME'], \n",
        "                                                                                  destination['NAME']]], \n",
        "                                                                                columns=['Origin', 'Destination']), \n",
        "                                                                   ignore_index=True)\n",
        "            else:\n",
        "                introduction_country[j, i] = bool(introduced)\n",
        "\n",
        "        locations.iloc[j, locations.columns.get_loc(\"Probability of introduction\")] = 1 - combined_probability_no_introduction\n",
        "\n",
        "    return entry_probabilities, establishment_probabilities, introduction_probabilities, introduction_country, locations, origin_destination\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ncBoqSTApVIR",
        "colab": {}
      },
      "source": [
        "def pandemic2(\n",
        "    trades,\n",
        "    distances,\n",
        "    locations,\n",
        "    alpha,\n",
        "    beta,\n",
        "    mu,\n",
        "    lamda_c,\n",
        "    phi,\n",
        "    sigma_epsilon,\n",
        "    sigma_h,\n",
        "    sigma_kappa,\n",
        "    sigma_phi,\n",
        "    sigma_T,\n",
        "    start_year\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of establishment, probability of entry, and\n",
        "    probability of introduction as an n x n matrices betweem every origin (i)\n",
        "    and destination (j) and update species presence and the combined\n",
        "    probability of presence for each origin (i) given climate similarity\n",
        "    between (i and j), host area in (j), ecological distrubance in (j), degree\n",
        "    of polyphagy of the pest species, trade volumes, distance, and\n",
        "    phytosanitary capacity.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    locations : data_frame\n",
        "        data frame of countries, species presence, phytosanitry capacity,\n",
        "        koppen climate classifications % of total area for each class.\n",
        "    trades : numpy.array\n",
        "        list (c) of n x n x t matrices where c is the # of commoditites,\n",
        "        n is the number of locations, and t is # of time steps\n",
        "    distances : numpy.array\n",
        "        n x n matrix of distances from one location to another where n is\n",
        "        number of locations.\n",
        "    alpha : float\n",
        "        A parameter that allows the equation to be adapated to various discrete\n",
        "        time steps\n",
        "    beta : float\n",
        "        A parameter that allows the equation to be adapted to various discrete\n",
        "        time steps\n",
        "    mu : float\n",
        "        The mortality rate of the pest or pathogen during transport\n",
        "    lamda_c : float\n",
        "        The commodity importance [0,1] of commodity (c) in transporting the\n",
        "        pest or pathogen\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_kappa : float\n",
        "        The climate dissimilarity normalizing constant\n",
        "    sigma_h : float\n",
        "        The host normalizing constant\n",
        "    sigma_epsilon : float\n",
        "        The ecological disturbance normalizing constant\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_phi : int\n",
        "        The degree of polyphagy normalizing constant\n",
        "    sigma_T : int\n",
        "        The trade volume normalizing constant\n",
        "    start_year : int\n",
        "        The year in which to start the simulation\n",
        "    random_seed : int (optional)\n",
        "        The number to use for initializing random values. If not provided, a new\n",
        "        value will be used for every simulation and results may differ for the\n",
        "        same input data and function parameters. If provided, the results of a\n",
        "        simulation can be reproduced.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_establishment : float\n",
        "        The probability of a pest to establish in the origin location\n",
        "\n",
        "    See Also\n",
        "    probability_of_entry : Calculates the probability of entry\n",
        "    probability_of_introduction : Calculates the probability of introduction\n",
        "        from the probability_of_establishment and probability_of_entry\n",
        "    \"\"\"\n",
        "\n",
        "    time_steps = trades.shape[0]\n",
        "    \n",
        "    entry_probabilities = np.empty_like(trades, dtype=float)\n",
        "    establishment_probabilities = np.empty_like(trades, dtype=float)\n",
        "    introduction_probabilities = np.empty_like(trades, dtype=float)\n",
        "    \n",
        "    introduction_countries = np.empty_like(trades, dtype=float)\n",
        "    locations[\"Probability of introduction\"] = np.zeros(shape=len(locations))\n",
        "    origin_destination = pd.DataFrame(columns=['Origin', 'Destination', 'Year'])\n",
        "    \n",
        "    date_list = pd.date_range(f'{str(start_year)}-01', \n",
        "                              f'{str(start_year + int(time_steps/12)-1)}-12', \n",
        "                              freq='MS').strftime(\"%Y%m\").tolist()\n",
        "    \n",
        "    for t in range(trades.shape[0]):\n",
        "        ts = date_list[t]\n",
        "        print('TIME STEP: ', ts)\n",
        "        trade = trades[t]\n",
        "        \n",
        "        ##TO DO: generalize for changing host percent area, static phytosanitary capacity, etc\n",
        "        locations[\"Host Percent Area\"] = locations[\"Host Percent Area\"]\n",
        "        # if locations[\"Host Percent Area T\" + str(t)] in locations.columns:\n",
        "        #   locations[\"Host Percent Area\"] = locations[\"Host Percent Area T\" + str(t)]\n",
        "        # else:\n",
        "        #   locations[\"Host Percent Area\"] = locations[\"Host Percent Area\"]\n",
        "        locations[\"Presence \" + str(ts)] = locations['Presence']\n",
        "        locations[\"Probability of introduction \"  + str(ts)] = locations[\"Probability of introduction\"]\n",
        "        locations[\"Phytosanitary Capacity\"] = locations ['Phytosanitary Capacity ' + ts[:4]]\n",
        "\n",
        "        ts_out = pandemic(\n",
        "        trade=trade,\n",
        "        distances=distances,\n",
        "        locations=locations,\n",
        "        alpha=alpha,\n",
        "        beta=beta,\n",
        "        mu=mu,\n",
        "        lamda_c=lamda_c,\n",
        "        phi=phi,\n",
        "        sigma_epsilon=sigma_epsilon,\n",
        "        sigma_h=sigma_h,\n",
        "        sigma_kappa=sigma_kappa,\n",
        "        sigma_phi=sigma_phi,\n",
        "        sigma_T=sigma_T,\n",
        "        time_step=ts)\n",
        "\n",
        "        establishment_probabilities[t] = ts_out[1]\n",
        "        entry_probabilities[t] = ts_out[0]\n",
        "        introduction_probabilities[t] = ts_out[2]\n",
        "        introduction_countries[t] = ts_out[3]\n",
        "        locations = ts_out[4]\n",
        "        origin_destination_ts = ts_out[5]\n",
        "        origin_destination_ts['TS'] = ts\n",
        "        if origin_destination.empty:\n",
        "            origin_destination = origin_destination_ts\n",
        "        else:\n",
        "            origin_destination = origin_destination.append(origin_destination_ts, ignore_index=True)\n",
        "\n",
        "    locations[\"Presence \" + str(ts)] = locations[\"Presence\"]\n",
        "    locations[\"Probability of introduction \"  + str(ts)] = locations[\"Probability of introduction\"]\n",
        "\n",
        "    return locations, entry_probabilities, establishment_probabilities, introduction_probabilities, origin_destination, introduction_countries, date_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zk5H1aSHemXY"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MoXOUa_qRTR7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "139dfc1b-9826-4d9b-f30d-9ab23558c8ae"
      },
      "source": [
        "countries = geopandas.read_file(data_dir + '/slf_model/inputs/countries4.gpkg', driver = 'GPKG')\n",
        "countries.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(236, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E8HXw_mLnHpK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "0bb72cf5-a3a3-45b4-f9e7-b9754dbdf7f8"
      },
      "source": [
        "# get distance n x n matrix\n",
        "distances = distance_between(countries)\n",
        "print(f'countries: {countries.shape}\\tdistances: {distances.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "countries: (236, 38)\tdistances: (236, 236)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-4-4149a9a2b54a>:19: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  centroids = shapefile.centroid.geometry\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2NtTQgGRjZs",
        "colab_type": "code",
        "colab": {},
        "outputId": "003b58bb-8023-4701-a4cd-eaca866064b0"
      },
      "source": [
        "gdp = pd.read_csv(data_dir + '/GDP/2000_2019_GDP_perCapita/gdp_perCapita_binned.csv', index_col =0)\n",
        "gdp['pc_mode'] = gdp[['2000', '2001', '2002', '2003', '2004',\n",
        "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
        "       '2014', '2015', '2016', '2017', '2018', '2019']].mode(axis=1)[0]\n",
        "year_cols = gdp.columns[3:-1]\n",
        "gdp.columns = np.where(gdp.columns.isin(year_cols), 'Phytosanitary Capacity ' + gdp.columns, gdp.columns)\n",
        "gdp.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>Country Code</th>\n",
              "      <th>Phytosanitary Capacity 2000</th>\n",
              "      <th>Phytosanitary Capacity 2001</th>\n",
              "      <th>Phytosanitary Capacity 2002</th>\n",
              "      <th>Phytosanitary Capacity 2003</th>\n",
              "      <th>Phytosanitary Capacity 2004</th>\n",
              "      <th>Phytosanitary Capacity 2005</th>\n",
              "      <th>Phytosanitary Capacity 2006</th>\n",
              "      <th>...</th>\n",
              "      <th>Phytosanitary Capacity 2011</th>\n",
              "      <th>Phytosanitary Capacity 2012</th>\n",
              "      <th>Phytosanitary Capacity 2013</th>\n",
              "      <th>Phytosanitary Capacity 2014</th>\n",
              "      <th>Phytosanitary Capacity 2015</th>\n",
              "      <th>Phytosanitary Capacity 2016</th>\n",
              "      <th>Phytosanitary Capacity 2017</th>\n",
              "      <th>Phytosanitary Capacity 2018</th>\n",
              "      <th>Phytosanitary Capacity 2019</th>\n",
              "      <th>pc_mode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>533</td>\n",
              "      <td>Aruba</td>\n",
              "      <td>ABW</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>...</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>AFG</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>...</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>Angola</td>\n",
              "      <td>AGO</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>...</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>Albania</td>\n",
              "      <td>ALB</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>...</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>AND</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>...</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    UN         NAME Country Code Phytosanitary Capacity 2000  \\\n",
              "1  533        Aruba          ABW                         mid   \n",
              "2    4  Afghanistan          AFG                         NaN   \n",
              "3   24       Angola          AGO                         low   \n",
              "4    8      Albania          ALB                         low   \n",
              "5   20      Andorra          AND                         mid   \n",
              "\n",
              "  Phytosanitary Capacity 2001 Phytosanitary Capacity 2002  \\\n",
              "1                         mid                         low   \n",
              "2                         NaN                         low   \n",
              "3                         low                         low   \n",
              "4                         low                         low   \n",
              "5                         mid                         mid   \n",
              "\n",
              "  Phytosanitary Capacity 2003 Phytosanitary Capacity 2004  \\\n",
              "1                         low                         low   \n",
              "2                         low                         low   \n",
              "3                         low                         low   \n",
              "4                         low                         low   \n",
              "5                         mid                         mid   \n",
              "\n",
              "  Phytosanitary Capacity 2005 Phytosanitary Capacity 2006  ...  \\\n",
              "1                         low                         low  ...   \n",
              "2                         low                         low  ...   \n",
              "3                         low                         low  ...   \n",
              "4                         low                         low  ...   \n",
              "5                         mid                         mid  ...   \n",
              "\n",
              "  Phytosanitary Capacity 2011 Phytosanitary Capacity 2012  \\\n",
              "1                         low                         low   \n",
              "2                         low                         low   \n",
              "3                         low                         low   \n",
              "4                         low                         low   \n",
              "5                         mid                         mid   \n",
              "\n",
              "  Phytosanitary Capacity 2013 Phytosanitary Capacity 2014  \\\n",
              "1                         low                         low   \n",
              "2                         low                         low   \n",
              "3                         low                         low   \n",
              "4                         low                         low   \n",
              "5                         mid                         mid   \n",
              "\n",
              "  Phytosanitary Capacity 2015 Phytosanitary Capacity 2016  \\\n",
              "1                         low                         low   \n",
              "2                         low                         low   \n",
              "3                         low                         low   \n",
              "4                         low                         low   \n",
              "5                         mid                         mid   \n",
              "\n",
              "  Phytosanitary Capacity 2017 Phytosanitary Capacity 2018  \\\n",
              "1                         low                         NaN   \n",
              "2                         low                         low   \n",
              "3                         low                         low   \n",
              "4                         low                         low   \n",
              "5                         mid                         mid   \n",
              "\n",
              "  Phytosanitary Capacity 2019 pc_mode  \n",
              "1                         NaN     low  \n",
              "2                         low     low  \n",
              "3                         low     low  \n",
              "4                         low     low  \n",
              "5                         mid     mid  \n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3BR9HGARjZx",
        "colab_type": "code",
        "colab": {},
        "outputId": "5f08a118-ab9e-43e0-e0f6-f673c8c7addf"
      },
      "source": [
        "countries = countries.merge(gdp, how='left', on='UN', suffixes = [None, '_y'])\n",
        "countries.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>AREA_x</th>\n",
              "      <th>centroid_lon</th>\n",
              "      <th>centroid_lat</th>\n",
              "      <th>Af</th>\n",
              "      <th>Am</th>\n",
              "      <th>Aw</th>\n",
              "      <th>BWh</th>\n",
              "      <th>BWk</th>\n",
              "      <th>...</th>\n",
              "      <th>Phytosanitary Capacity 2011</th>\n",
              "      <th>Phytosanitary Capacity 2012</th>\n",
              "      <th>Phytosanitary Capacity 2013</th>\n",
              "      <th>Phytosanitary Capacity 2014</th>\n",
              "      <th>Phytosanitary Capacity 2015</th>\n",
              "      <th>Phytosanitary Capacity 2016</th>\n",
              "      <th>Phytosanitary Capacity 2017</th>\n",
              "      <th>Phytosanitary Capacity 2018</th>\n",
              "      <th>Phytosanitary Capacity 2019</th>\n",
              "      <th>pc_mode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>65209</td>\n",
              "      <td>7.350040e+06</td>\n",
              "      <td>3.983398e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.268111</td>\n",
              "      <td>0.028333</td>\n",
              "      <td>...</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2740</td>\n",
              "      <td>2.234000e+06</td>\n",
              "      <td>5.005271e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>238174</td>\n",
              "      <td>2.930336e+05</td>\n",
              "      <td>3.249422e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.875809</td>\n",
              "      <td>0.044779</td>\n",
              "      <td>...</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>American Samoa</td>\n",
              "      <td>20</td>\n",
              "      <td>-1.896905e+07</td>\n",
              "      <td>-1.596503e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>NaN</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>0</td>\n",
              "      <td>1.754048e+05</td>\n",
              "      <td>5.214610e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   UN            NAME  AREA_x  centroid_lon  centroid_lat   Af   Am   Aw  \\\n",
              "0   4     Afghanistan   65209  7.350040e+06  3.983398e+06  0.0  0.0  0.0   \n",
              "1   8         Albania    2740  2.234000e+06  5.005271e+06  0.0  0.0  0.0   \n",
              "2  12         Algeria  238174  2.930336e+05  3.249422e+06  0.0  0.0  0.0   \n",
              "3  16  American Samoa      20 -1.896905e+07 -1.596503e+06  1.0  0.0  0.0   \n",
              "4  20         Andorra       0  1.754048e+05  5.214610e+06  0.0  0.0  0.0   \n",
              "\n",
              "        BWh       BWk  ...  Phytosanitary Capacity 2011  \\\n",
              "0  0.268111  0.028333  ...                          low   \n",
              "1  0.000000  0.000000  ...                          low   \n",
              "2  0.875809  0.044779  ...                          low   \n",
              "3  0.000000  0.000000  ...                          low   \n",
              "4  0.000000  0.000000  ...                          mid   \n",
              "\n",
              "   Phytosanitary Capacity 2012  Phytosanitary Capacity 2013  \\\n",
              "0                          low                          low   \n",
              "1                          low                          low   \n",
              "2                          low                          low   \n",
              "3                          low                          low   \n",
              "4                          mid                          mid   \n",
              "\n",
              "   Phytosanitary Capacity 2014  Phytosanitary Capacity 2015  \\\n",
              "0                          low                          low   \n",
              "1                          low                          low   \n",
              "2                          low                          low   \n",
              "3                          low                          low   \n",
              "4                          mid                          mid   \n",
              "\n",
              "   Phytosanitary Capacity 2016  Phytosanitary Capacity 2017  \\\n",
              "0                          low                          low   \n",
              "1                          low                          low   \n",
              "2                          low                          low   \n",
              "3                          low                          low   \n",
              "4                          mid                          mid   \n",
              "\n",
              "   Phytosanitary Capacity 2018  Phytosanitary Capacity 2019  pc_mode  \n",
              "0                          low                          low      low  \n",
              "1                          low                          low      low  \n",
              "2                          low                          low      low  \n",
              "3                          low                          NaN      low  \n",
              "4                          mid                          mid      mid  \n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5rm4kwTRjZ3",
        "colab_type": "code",
        "colab": {},
        "outputId": "1fa84a04-167f-4713-a263-91b18a8e11fb"
      },
      "source": [
        "gdp_dict = {'low': .25,\n",
        "            'mid': .7,\n",
        "            'high': .9,\n",
        "            np.nan: 0}\n",
        "countries.replace(gdp_dict,\n",
        "                  inplace=True)\n",
        "countries.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>AREA_x</th>\n",
              "      <th>centroid_lon</th>\n",
              "      <th>centroid_lat</th>\n",
              "      <th>Af</th>\n",
              "      <th>Am</th>\n",
              "      <th>Aw</th>\n",
              "      <th>BWh</th>\n",
              "      <th>BWk</th>\n",
              "      <th>...</th>\n",
              "      <th>Phytosanitary Capacity 2011</th>\n",
              "      <th>Phytosanitary Capacity 2012</th>\n",
              "      <th>Phytosanitary Capacity 2013</th>\n",
              "      <th>Phytosanitary Capacity 2014</th>\n",
              "      <th>Phytosanitary Capacity 2015</th>\n",
              "      <th>Phytosanitary Capacity 2016</th>\n",
              "      <th>Phytosanitary Capacity 2017</th>\n",
              "      <th>Phytosanitary Capacity 2018</th>\n",
              "      <th>Phytosanitary Capacity 2019</th>\n",
              "      <th>pc_mode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>65209</td>\n",
              "      <td>7.350040e+06</td>\n",
              "      <td>3.983398e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.268111</td>\n",
              "      <td>0.028333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2740</td>\n",
              "      <td>2.234000e+06</td>\n",
              "      <td>5.005271e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>238174</td>\n",
              "      <td>2.930336e+05</td>\n",
              "      <td>3.249422e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.875809</td>\n",
              "      <td>0.044779</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>American Samoa</td>\n",
              "      <td>20</td>\n",
              "      <td>-1.896905e+07</td>\n",
              "      <td>-1.596503e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>0</td>\n",
              "      <td>1.754048e+05</td>\n",
              "      <td>5.214610e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 61 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   UN            NAME  AREA_x  centroid_lon  centroid_lat   Af   Am   Aw  \\\n",
              "0   4     Afghanistan   65209  7.350040e+06  3.983398e+06  0.0  0.0  0.0   \n",
              "1   8         Albania    2740  2.234000e+06  5.005271e+06  0.0  0.0  0.0   \n",
              "2  12         Algeria  238174  2.930336e+05  3.249422e+06  0.0  0.0  0.0   \n",
              "3  16  American Samoa      20 -1.896905e+07 -1.596503e+06  1.0  0.0  0.0   \n",
              "4  20         Andorra       0  1.754048e+05  5.214610e+06  0.0  0.0  0.0   \n",
              "\n",
              "        BWh       BWk  ...  Phytosanitary Capacity 2011  \\\n",
              "0  0.268111  0.028333  ...                         0.25   \n",
              "1  0.000000  0.000000  ...                         0.25   \n",
              "2  0.875809  0.044779  ...                         0.25   \n",
              "3  0.000000  0.000000  ...                         0.25   \n",
              "4  0.000000  0.000000  ...                         0.70   \n",
              "\n",
              "   Phytosanitary Capacity 2012  Phytosanitary Capacity 2013  \\\n",
              "0                         0.25                         0.25   \n",
              "1                         0.25                         0.25   \n",
              "2                         0.25                         0.25   \n",
              "3                         0.25                         0.25   \n",
              "4                         0.70                         0.70   \n",
              "\n",
              "   Phytosanitary Capacity 2014  Phytosanitary Capacity 2015  \\\n",
              "0                         0.25                         0.25   \n",
              "1                         0.25                         0.25   \n",
              "2                         0.25                         0.25   \n",
              "3                         0.25                         0.25   \n",
              "4                         0.70                         0.70   \n",
              "\n",
              "   Phytosanitary Capacity 2016  Phytosanitary Capacity 2017  \\\n",
              "0                         0.25                         0.25   \n",
              "1                         0.25                         0.25   \n",
              "2                         0.25                         0.25   \n",
              "3                         0.25                         0.25   \n",
              "4                         0.70                         0.70   \n",
              "\n",
              "   Phytosanitary Capacity 2018  Phytosanitary Capacity 2019  pc_mode  \n",
              "0                         0.25                         0.25     0.25  \n",
              "1                         0.25                         0.25     0.25  \n",
              "2                         0.25                         0.25     0.25  \n",
              "3                         0.25                         0.00     0.25  \n",
              "4                         0.70                         0.70     0.70  \n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fz9yQAm0yG-j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f566a65-0846-4d86-dc5c-513e0068f633"
      },
      "source": [
        "## path to directory  \n",
        "#directory_path = \"/content/drive/Shared drives/APHIS  Projects/Pandemic/Data/slf_model/inputs/annual/all_commodities/*.csv\" #codes 6801 - 6815\n",
        "#directory_path = \"/content/drive/Shared drives/APHIS  Projects/Pandemic/Data/slf_model/inputs/annual/select_stone/*.csv\" #codes 6801-6804\n",
        "directory_path = data_dir + \"/slf_model/inputs/monthly/select_commodities/*.csv\" #codes 6801-6804\n",
        "file_list_historical = glob.glob(directory_path)\n",
        "file_list_historical.sort()\n",
        "\n",
        "file_list_forecast = glob.glob(data_dir + '/slf_model/inputs/monthly/forecast/static/*.csv')\n",
        "file_list_forecast.sort()\n",
        "\n",
        "file_list = file_list_historical #+ file_list_forecast\n",
        "\n",
        "trades = np.zeros(shape = (len(file_list), distances.shape[0], distances.shape[0]))\n",
        "for i in range(len(file_list)):\n",
        "    trades[i] = pd.read_csv(file_list[i], sep = \",\", header= 0, index_col=0, encoding='latin1').values\n",
        "\n",
        "traded = pd.read_csv(file_list[1], sep = \",\",header= 0, index_col=0, encoding='latin1')\n",
        "trades.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(228, 236, 236)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aNKviMY3Y5nX",
        "colab": {}
      },
      "source": [
        "#Native range to start presence = True at T0\n",
        "china_index = countries.index[countries['NAME'] == 'China'][0]\n",
        "viet_nam_index = countries.index[countries['NAME'] == 'Viet Nam'][0]\n",
        "india_index = countries.index[countries['NAME'] == 'India'][0]\n",
        "native_countries_list = ['China', 'Viet Nam', 'India']\n",
        "\n",
        "#Known Introductions \n",
        "skorea_index = countries.index[countries['NAME'] == 'Korea, Republic of'][0]\n",
        "japan_index = countries.index[countries['NAME'] == 'Japan'][0]\n",
        "us_index = countries.index[countries['NAME'] == 'United States'][0]\n",
        "known_introductions_list = ['United States', 'Korea, Republic of', 'Japan']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I-SqkRkEesvc"
      },
      "source": [
        "# **Model Parameters & Runs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl7J_6NdRjad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### notes on numbers used and rationale\n",
        "## Parameters that should be calibrated and validated as much as possible\n",
        "# alpha - just choose these as starting values\n",
        "# beta - just choose these as starting values\n",
        "# mu - just choose these as starting values\n",
        "\n",
        "## Parameters that we can set based on underlying data to normalize\n",
        "# sigma_h = 1 - the mean of the host percent area (not sure that this is the best assumption here but normalizes and gives results that make sense here)\n",
        "# sigma_phi = 1 (assummes that a specialist that feeds on only one type of host will have a harder time invading than a generalist) (needs to be an integer)\n",
        "# sigma_kappa = just selected a value but plan on 1 - mean of the koppen climate matches\n",
        "# sigma_epsilon doesn't matter right now (we aren't using ecological disturbance this part of the equation drops out (i.e. changing this value doesn't afffect the simulation))\n",
        "# sigma_T - I still need to adjust this "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j9qNJz5tthVR",
        "colab": {}
      },
      "source": [
        "alpha = 0.2 #@param {type:\"number\"}\n",
        "beta = 0.2 #@param {type:\"number\"}\n",
        "mu = 0.00015 #@param {type:\"number\"}\n",
        "lamda_c = 1 #@param {type:\"number\"}\n",
        "phi = 2 #@param {type:\"integer\"}\n",
        "sigma_epsilon = 0.5 #@param {type:\"number\"}\n",
        "sigma_h = 1 - 0.16 #@param {type:\"number\"}\n",
        "sigma_kappa = 1 - 0.3 #@param {type:\"number\"}\n",
        "sigma_phi =  1 #@param {type:\"integer\"}\n",
        "sigma_T = 9500 #@param {type:\"integer\"}\n",
        "start_year = 2000 #@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxFLsHuPRjaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_num = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M5FtYWb_BH6m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "652cf1d6-beaf-49ac-f5ce-80be9f8e9c1a"
      },
      "source": [
        "# Runs the full model\n",
        "np.random.seed(seed=8642)\n",
        "trades = trades\n",
        "distances = distances\n",
        "locations = countries\n",
        "prob = np.zeros(len(countries.index))\n",
        "pres_ts0 = [False] *len(prob)\n",
        "pres_ts0[china_index] = True \n",
        "pres_ts0[viet_nam_index] = True\n",
        "pres_ts0[india_index] = True\n",
        "locations[\"Presence\"] = pres_ts0\n",
        "#locations[\"Phytosanitary Capacity\"] = prob\n",
        "\n",
        "print('PARAMETER VALUES:')\n",
        "print(f'alpha: {alpha}\\tbeta: {beta}\\tmu: {mu}')\n",
        "print(f'sigma_h: {sigma_h}\\tsigma_kappa: {sigma_kappa}\\tsigma_T: {sigma_T}')\n",
        "\n",
        "# comms = directory_path.split('/')[9]\n",
        "# time_agg = directory_path.split('/')[8]\n",
        "comms = 'select_commodities'\n",
        "time_agg = 'monthly'\n",
        "\n",
        "print(f'Commodities: {comms} @ {time_agg}')\n",
        "print(f'GPD vals:\\n{gdp_dict}')\n",
        "\n",
        "e = pandemic2(\n",
        "    trades=trades,\n",
        "    distances=distances,\n",
        "    locations=locations,\n",
        "    alpha=alpha,\n",
        "    beta=beta,\n",
        "    mu=mu,\n",
        "    lamda_c=lamda_c,\n",
        "    phi=phi,\n",
        "    sigma_epsilon=sigma_epsilon,\n",
        "    sigma_h=sigma_h,\n",
        "    sigma_kappa=sigma_kappa,\n",
        "    sigma_phi=sigma_phi,\n",
        "    sigma_T=sigma_T,\n",
        "    start_year=start_year\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PARAMETER VALUES:\n",
            "alpha: 0.2\tbeta: 0.2\tmu: 0.00015\n",
            "sigma_h: 0.84\tsigma_kappa: 0.7\tsigma_T: 9500\n",
            "Commodities: select_commodities @ monthly\n",
            "GPD vals:\n",
            "{'low': 0.25, 'mid': 0.7, 'high': 0.9, nan: 0}\n",
            "TIME STEP:  200001\n",
            "TIME STEP:  200002\n",
            "TIME STEP:  200003\n",
            "TIME STEP:  200004\n",
            "TIME STEP:  200005\n",
            "TIME STEP:  200006\n",
            "TIME STEP:  200007\n",
            "TIME STEP:  200008\n",
            "TIME STEP:  200009\n",
            "TIME STEP:  200010\n",
            "TIME STEP:  200011\n",
            "TIME STEP:  200012\n",
            "TIME STEP:  200101\n",
            "TIME STEP:  200102\n",
            "TIME STEP:  200103\n",
            "TIME STEP:  200104\n",
            "TIME STEP:  200105\n",
            "TIME STEP:  200106\n",
            "TIME STEP:  200107\n",
            "TIME STEP:  200108\n",
            "TIME STEP:  200109\n",
            "TIME STEP:  200110\n",
            "TIME STEP:  200111\n",
            "TIME STEP:  200112\n",
            "TIME STEP:  200201\n",
            "TIME STEP:  200202\n",
            "TIME STEP:  200203\n",
            "TIME STEP:  200204\n",
            "TIME STEP:  200205\n",
            "TIME STEP:  200206\n",
            "TIME STEP:  200207\n",
            "TIME STEP:  200208\n",
            "TIME STEP:  200209\n",
            "TIME STEP:  200210\n",
            "TIME STEP:  200211\n",
            "TIME STEP:  200212\n",
            "TIME STEP:  200301\n",
            "TIME STEP:  200302\n",
            "TIME STEP:  200303\n",
            "TIME STEP:  200304\n",
            "TIME STEP:  200305\n",
            "TIME STEP:  200306\n",
            "TIME STEP:  200307\n",
            "TIME STEP:  200308\n",
            "TIME STEP:  200309\n",
            "TIME STEP:  200310\n",
            "TIME STEP:  200311\n",
            "TIME STEP:  200312\n",
            "TIME STEP:  200401\n",
            "TIME STEP:  200402\n",
            "TIME STEP:  200403\n",
            "TIME STEP:  200404\n",
            "TIME STEP:  200405\n",
            "TIME STEP:  200406\n",
            "TIME STEP:  200407\n",
            "TIME STEP:  200408\n",
            "TIME STEP:  200409\n",
            "TIME STEP:  200410\n",
            "TIME STEP:  200411\n",
            "TIME STEP:  200412\n",
            "TIME STEP:  200501\n",
            "TIME STEP:  200502\n",
            "TIME STEP:  200503\n",
            "TIME STEP:  200504\n",
            "TIME STEP:  200505\n",
            "TIME STEP:  200506\n",
            "TIME STEP:  200507\n",
            "TIME STEP:  200508\n",
            "TIME STEP:  200509\n",
            "TIME STEP:  200510\n",
            "TIME STEP:  200511\n",
            "TIME STEP:  200512\n",
            "TIME STEP:  200601\n",
            "TIME STEP:  200602\n",
            "TIME STEP:  200603\n",
            "TIME STEP:  200604\n",
            "TIME STEP:  200605\n",
            "TIME STEP:  200606\n",
            "TIME STEP:  200607\n",
            "TIME STEP:  200608\n",
            "TIME STEP:  200609\n",
            "TIME STEP:  200610\n",
            "TIME STEP:  200611\n",
            "TIME STEP:  200612\n",
            "TIME STEP:  200701\n",
            "TIME STEP:  200702\n",
            "TIME STEP:  200703\n",
            "TIME STEP:  200704\n",
            "TIME STEP:  200705\n",
            "TIME STEP:  200706\n",
            "TIME STEP:  200707\n",
            "TIME STEP:  200708\n",
            "TIME STEP:  200709\n",
            "TIME STEP:  200710\n",
            "TIME STEP:  200711\n",
            "TIME STEP:  200712\n",
            "TIME STEP:  200801\n",
            "TIME STEP:  200802\n",
            "TIME STEP:  200803\n",
            "TIME STEP:  200804\n",
            "TIME STEP:  200805\n",
            "TIME STEP:  200806\n",
            "TIME STEP:  200807\n",
            "TIME STEP:  200808\n",
            "TIME STEP:  200809\n",
            "TIME STEP:  200810\n",
            "TIME STEP:  200811\n",
            "TIME STEP:  200812\n",
            "TIME STEP:  200901\n",
            "TIME STEP:  200902\n",
            "TIME STEP:  200903\n",
            "TIME STEP:  200904\n",
            "TIME STEP:  200905\n",
            "TIME STEP:  200906\n",
            "TIME STEP:  200907\n",
            "TIME STEP:  200908\n",
            "TIME STEP:  200909\n",
            "TIME STEP:  200910\n",
            "TIME STEP:  200911\n",
            "TIME STEP:  200912\n",
            "TIME STEP:  201001\n",
            "\t China --> Korea, Republic of\n",
            "TIME STEP:  201002\n",
            "TIME STEP:  201003\n",
            "\t China --> Korea, Republic of\n",
            "TIME STEP:  201004\n",
            "\t China --> Pakistan\n",
            "TIME STEP:  201005\n",
            "TIME STEP:  201006\n",
            "TIME STEP:  201007\n",
            "TIME STEP:  201008\n",
            "TIME STEP:  201009\n",
            "TIME STEP:  201010\n",
            "TIME STEP:  201011\n",
            "TIME STEP:  201012\n",
            "TIME STEP:  201101\n",
            "\t China --> Iran (Islamic Republic of)\n",
            "TIME STEP:  201102\n",
            "\t China --> Iran (Islamic Republic of)\n",
            "TIME STEP:  201103\n",
            "TIME STEP:  201104\n",
            "TIME STEP:  201105\n",
            "TIME STEP:  201106\n",
            "TIME STEP:  201107\n",
            "TIME STEP:  201108\n",
            "TIME STEP:  201109\n",
            "TIME STEP:  201110\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M67qQ8yfezAA"
      },
      "source": [
        "# **View and Save Output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2lDHwirfmeY",
        "colab": {}
      },
      "source": [
        "#Save model output objects\n",
        "check = e[0] #locations\n",
        "prob_entry = e[1]\n",
        "prob_est = e[2] #changed from [3] -- think that is introduced \n",
        "prob_intro = e[3]\n",
        "origin_dst = e[4] #previously test = e[4]  #origin_destination\n",
        "country_intro = e[5]\n",
        "date_list_out = e[6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEcsceZ-RjbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr_dict = {'prob_entry': 'probability_of_entry',\n",
        "           'prob_intro': 'probability_of_introduction',\n",
        "           'prob_est': 'probability_of_establishment',\n",
        "           'country_introduction': 'country_introduction'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlwGT_hKRjbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outpath = f'{data_dir}/slf_model/outputs/{time_agg}/{comms}/phytosanitary/run{run_num}/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0SrD2995mgFT",
        "colab": {}
      },
      "source": [
        "def create_model_dirs(run_num, outpath, output_dict):\n",
        "    os.makedirs(outpath, exist_ok = True)\n",
        "    \n",
        "    for key in output_dict.keys():\n",
        "        os.makedirs(outpath + key, exist_ok = True)\n",
        "        print(outpath + key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huMWAH9vRjbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_model_dirs(run_num = run_num,\n",
        "                  outpath = outpath,\n",
        "                  output_dict = arr_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAt7hmXfRjb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_model_metadata(outpath, run_num, native_countries_list, comms, time_agg, gdp_dict, main_model_output, select_origin_dst):\n",
        "    with open(f'{outpath}run{run_num}_meta.txt', 'w') as file:\n",
        "        file.write(f'PARAMETER VALS: \\n\\talpha: {alpha}\\n\\tbeta: {beta}\\n\\tmu: {mu}')\n",
        "        file.write(f'\\tsigma_h: {sigma_h}\\n\\tsigma_kappa: {sigma_kappa}\\n\\tsigma_T: {sigma_T}\\n\\n')\n",
        "        file.write(f'NATIVE COUNTRIES AT T0:\\n\\t{native_countries_list}')\n",
        "        file.write(f'\\nCOMMODITIES: {comms} @ {time_agg}\\n\\n')\n",
        "        file.write('PHYTOSANITARY CAPACITY:\\n\\tDynamic by Year\\n\\tAggregated by equal intervals (i.e., \"Length\")\\n')\n",
        "        file.write(f'\\tGPD vals:{gdp_dict}\\n\\n')\n",
        "        file.write('COUNTRY INTRODUCTIONS:')\n",
        "        file.write(f'\\nTotal Number of Countries: {main_model_output[\"Presence 201812\"].value_counts()[1]}')\n",
        "        file.write(f'\\n{select_origin_dst.to_string()}')\n",
        "        file.close()\n",
        "        print(f'saving: {outpath}run{run_num}_meta.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr7iXcnrRjb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_model_metadata(outpath = outpath,\n",
        "                        run_num = run_num,\n",
        "                        native_countries_list = native_countries_list,\n",
        "                        comms = comms, \n",
        "                        time_agg = time_agg,\n",
        "                        gdp_dict = gdp_dict, \n",
        "                        main_model_output = e[0],\n",
        "                        select_origin_dst = origin_dst[origin_dst['Destination'].isin(known_introductions_list)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE6kkaVkRjcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_monthly_model_output(model_output_object, columns_to_drop, outpath, run_num):\n",
        "    check = model_output_object[0] #locations\n",
        "    prob_entry = model_output_object[1]\n",
        "    prob_est = model_output_object[2] \n",
        "    prob_intro = model_output_object[3]\n",
        "    origin_dst = model_output_object[4] \n",
        "    country_intro = model_output_object[5]\n",
        "    date_list_out = model_output_object[6]\n",
        "    \n",
        "    out_df = check.drop(columns_to_drop, axis=1)\n",
        "    out_df[\"geometry\"] = [MultiPolygon([feature]) if type(feature) == Polygon else feature for feature in out_df[\"geometry\"]]\n",
        "    out_df.to_file(outpath + f'pandemic_output.geojson', driver='GeoJSON')\n",
        "\n",
        "    origin_dst.to_csv(outpath + f'origin_destination.csv')\n",
        "    \n",
        "    for i in range(0, len(date_list_out)):\n",
        "        ts = date_list_out[i]\n",
        "        \n",
        "        pro_entry_pd = pd.DataFrame(prob_entry[i])\n",
        "        pro_entry_pd.columns = traded.columns\n",
        "        pro_entry_pd.index = traded.index\n",
        "        pro_entry_pd.to_csv(outpath + f\"prob_entry/probability_of_entry_{str(ts)}.csv\", float_format='%.2f', na_rep=\"NAN!\")\n",
        "        \n",
        "        pro_intro_pd = pd.DataFrame(prob_intro[i])\n",
        "        pro_intro_pd.columns = traded.columns\n",
        "        pro_intro_pd.index = traded.index\n",
        "        pro_intro_pd.to_csv(outpath + f\"prob_intro/probability_of_introduction_{str(ts)}.csv\", float_format='%.2f', na_rep=\"NAN!\")\n",
        "        \n",
        "        pro_est_pd = pd.DataFrame(prob_est[i])\n",
        "        pro_est_pd.columns = traded.columns\n",
        "        pro_est_pd.index = traded.index\n",
        "        pro_est_pd.to_csv(outpath + f\"prob_est/probability_of_establishment_{str(ts)}.csv\", float_format='%.2f', na_rep=\"NAN!\")\n",
        "        \n",
        "        country_int_pd = pd.DataFrame(country_intro[i])\n",
        "        country_int_pd.columns = traded.columns\n",
        "        country_int_pd.index = traded.index\n",
        "        country_int_pd.to_csv(outpath + f\"country_introduction/country_introduction_{str(ts)}.csv\", float_format='%.2f', na_rep=\"NAN!\")\n",
        "    \n",
        "    return out_df, date_list_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pA4PNV3crGwN",
        "colab": {}
      },
      "source": [
        "columns_to_drop = ['AREA_x', \n",
        "                   'Af',\n",
        "                   'Am',\n",
        "                   'Aw',\n",
        "                   'BWh',\n",
        "                   'BWk',\n",
        "                   'BSh',\n",
        "                   'BSk',\n",
        "                   'Csa',\n",
        "                   'Csb',\n",
        "                   'Csc',\n",
        "                   'Cwa',\n",
        "                   'Cwb',\n",
        "                   'Cwc',\n",
        "                   'Cfa',\n",
        "                   'Cfb',\n",
        "                   'Cfc',\n",
        "                   'Dsa',\n",
        "                   'Dsb',\n",
        "                   'Dsc',\n",
        "                   'Dsd',\n",
        "                   'Dwa',\n",
        "                   'Dwb',\n",
        "                   'Dwc',\n",
        "                   'Dwd',\n",
        "                   'Dfa',\n",
        "                   'Dfb',\n",
        "                   'Dfc',\n",
        "                   'Dfd',\n",
        "                   'ET',\n",
        "                   'EF',\n",
        "                   'NAME_y','Phytosanitary Capacity 2000',\n",
        "                   'Phytosanitary Capacity 2001',\n",
        "                   'Phytosanitary Capacity 2002',\n",
        "                   'Phytosanitary Capacity 2003',\n",
        "                   'Phytosanitary Capacity 2004',\n",
        "                   'Phytosanitary Capacity 2005',\n",
        "                   'Phytosanitary Capacity 2006',\n",
        "                   'Phytosanitary Capacity 2007',\n",
        "                   'Phytosanitary Capacity 2008',\n",
        "                   'Phytosanitary Capacity 2009',\n",
        "                   'Phytosanitary Capacity 2010',\n",
        "                   'Phytosanitary Capacity 2011',\n",
        "                   'Phytosanitary Capacity 2012',\n",
        "                   'Phytosanitary Capacity 2013',\n",
        "                   'Phytosanitary Capacity 2014',\n",
        "                   'Phytosanitary Capacity 2015',\n",
        "                   'Phytosanitary Capacity 2016',\n",
        "                   'Phytosanitary Capacity 2017',\n",
        "                   'Phytosanitary Capacity 2018',\n",
        "                   'Phytosanitary Capacity 2019',\n",
        "                   'Presence',\n",
        "                   'Probability of introduction',\n",
        "                   'pc_mode']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atf4iqj4RjcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_df, date_list_out = save_monthly_model_output(model_output_object = e,\n",
        "                                   columns_to_drop = columns_to_drop,\n",
        "                                   outpath = f'{data_dir}/slf_model/outputs/{time_agg}/{comms}/phytosanitary/run{run_num}/', \n",
        "                                   run_num = run_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3VLwlnSRjcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def aggregate_monthly_output_to_annual(start_year, date_list_out, formatted_geojson):\n",
        "    annual_ts_list = range(start_year, int(len(date_list_out)/12), 1)\n",
        "    presence_cols = [c for c in formatted_geojson.columns if c.startswith('Presence')]\n",
        "    prob_intro_cols = [c for c in formatted_geojson.columns if c.startswith('Probability of introduction')]\n",
        "    nh_list = ['09', '10', '11', '12', '01', '02', '03', '04']\n",
        "    sh_list = ['04', '05', '06', '07', '08', '09', '10']\n",
        "\n",
        "    for year in annual_ts_list:\n",
        "        prob_cols = [c for c in prob_intro_cols if str(year) in c]\n",
        "        nh_prob_cols = [x for x in prob_cols if x[-2:] in nh_list]\n",
        "        sh_prob_cols = [x for x in prob_cols if x[-2:] in sh_list]\n",
        "        ##TO DO: add in check for seasonality flag, otherwise use average for entire year\n",
        "        formatted_geojson[f'Avg Probability of introduction {str(year)}'] = (np.where(formatted_geojson['centroid_lat']>=0, \n",
        "                                                                  formatted_geojson[nh_prob_cols].mean(axis=1), \n",
        "                                                                  formatted_geojson[sh_prob_cols].mean(axis=1)))\n",
        "        formatted_geojson[f'Max Probability of introduction {str(year)}'] = np.max(formatted_geojson[prob_cols], axis=1)\n",
        "        formatted_geojson[f'Presence {year}'] = formatted_geojson[f'Presence {year}12']\n",
        "    \n",
        "    formatted_geojson.to_file(outpath + f'pandemic_output_aggregated.geojson', driver='GeoJSON')\n",
        "    out_df = pd.DataFrame(formatted_geojson)\n",
        "    out_df.drop(['geometry'], axis=1, inplace=True)\n",
        "    out_df.to_csv(outpath + f'pandemic_output_aggregated.csv', float_format='%.2f', na_rep=\"NAN!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqVloWzCRjcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aggregate_monthly_output_to_annual(start_year = start_year,\n",
        "                                   date_list_out = date_list_out,\n",
        "                                   formatted_geojson = out_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z1PzZdaRjco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def aggregate_monthly_array_outputs(num_time_steps, output_type, model_arr, output_name, start_year, out_path, run_num):\n",
        "    t=0\n",
        "    for i in range(0, num_time_steps, 12):\n",
        "        avg_arr = (model_arr[i]+ \n",
        "            model_arr[i+1]+\n",
        "            model_arr[i+2]+ \n",
        "            model_arr[i+3]+\n",
        "            model_arr[i+4]+\n",
        "            model_arr[i+5]+\n",
        "            model_arr[i+6]+ \n",
        "            model_arr[i+7]+\n",
        "            model_arr[i+8]+ \n",
        "            model_arr[i+9]+\n",
        "            model_arr[i+10]+ \n",
        "            model_arr[i+11]) / 12\n",
        "        avg_df = pd.DataFrame(avg_arr)\n",
        "        avg_df.columns = traded.columns\n",
        "        avg_df.index = traded.index\n",
        "        avg_df.to_csv(outpath +  f\"{output_type}/avg_{output_name}_{str(start_year + t)}.csv\", float_format='%.2f', na_rep=\"NAN!\")\n",
        "\n",
        "        max_arr = np.maximum.reduce([model_arr[i],\n",
        "                                    model_arr[i+1],\n",
        "                                    model_arr[i+2], \n",
        "                                    model_arr[i+3],\n",
        "                                    model_arr[i+4],\n",
        "                                    model_arr[i+5],\n",
        "                                    model_arr[i+6], \n",
        "                                    model_arr[i+7],\n",
        "                                    model_arr[i+8], \n",
        "                                    model_arr[i+9],\n",
        "                                    model_arr[i+10], \n",
        "                                    model_arr[i+11]])\n",
        "        max_df = pd.DataFrame(max_arr)\n",
        "        max_df.columns = traded.columns\n",
        "        max_df.index = traded.index\n",
        "        max_df.to_csv(outpath +  f\"{output_type}/max_{output_name}_{str(start_year + t)}.csv\", float_format='%.2f', na_rep=\"NAN!\")\n",
        "\n",
        "        t += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Gf7X1XfRjcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aggregate_monthly_array_outputs(num_time_steps = prob_entry.shape[0],\n",
        "                                output_type = 'prob_entry', \n",
        "                                model_arr = prob_entry,\n",
        "                                output_name = 'probability_of_entry',\n",
        "                                start_year = start_year,\n",
        "                                out_path = outpath,\n",
        "                                run_num = run_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZhN-8NnX2Gz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aggregate_monthly_array_outputs(num_time_steps = prob_est.shape[0],\n",
        "                                output_type = 'prob_est', \n",
        "                                model_arr = prob_est,\n",
        "                                output_name = 'probability_of_establishment',\n",
        "                                start_year = start_year,\n",
        "                                out_path = outpath,\n",
        "                                run_num = run_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KScAdjwX2Z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aggregate_monthly_array_outputs(num_time_steps = prob_intro.shape[0],\n",
        "                                output_type = 'prob_intro', \n",
        "                                model_arr = prob_intro,\n",
        "                                output_name = 'probability_of_introduction',\n",
        "                                start_year = start_year,\n",
        "                                out_path = outpath,\n",
        "                                run_num = run_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4Y8Qvq6Rjc0",
        "colab_type": "text"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x7nDrCi2B20-",
        "colab": {}
      },
      "source": [
        "# check = e[0]\n",
        "# # check_centroids = check.centroid\n",
        "# check['Presence T25'].values.sum()\n",
        "\n",
        "\n",
        "# check['Probability of introduction T2'].values\n",
        "# np.zeros(shape=len(locations))\n",
        "# check.columns\n",
        "\n",
        "# check.plot(column='Presence_T')\n",
        "# check.plot(column='Probability of introduction T1')\n",
        "# col_name = 'Presence T' +str(i)\n",
        "\n",
        "# for i in range(26):\n",
        "#   col_name = 'Presence ' +str(i + start_year)\n",
        "#   col_name2 = 'Probability of introduction ' +str(i + start_year)\n",
        "#   check_centroids = check.loc[check[col_name]].centroid\n",
        "#   fig, ax = plt.subplots(figsize=(28,14))\n",
        "#   check.plot(ax=ax, column=col_name2, legend = True, figsize=(30, 15))\n",
        "#   check_centroids.plot(ax = ax, color = 'red')\n",
        "#   plt.title('Citrust Pest presence in ' + str(i + start_year), color='white')\n",
        "#   # plt.legend()\n",
        "#   plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCcbTRGeRjdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = geopandas.read_file(f'{data_dir}/slf_model/outputs/annual/all_commodities/geojson/pandemic_output_test1.geojson',\n",
        "                          driver='GeoJSON')\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gumy7aGCf7xU",
        "colab": {}
      },
      "source": [
        "## write geojson outputs for MapBox example\n",
        "outpath = '/content/drive/Shared drives/APHIS  Projects/Pandemic/Data/slf_model/outputs/'\n",
        "## write out csv for origin destination year pairs.\n",
        "# test.to_csv(outpath + \"pandemic_output_origin_destination.csv\")\n",
        "check = e[0]\n",
        "# check.drop(columns=['Host Percent Area T0',\n",
        "#        'Host Percent Area T1', 'Host Percent Area T2', 'Host Percent Area T3',\n",
        "#        'Host Percent Area T4', 'Host Percent Area T5', 'Host Percent Area T6',\n",
        "#        'Host Percent Area T7', 'Host Percent Area T8', 'Host Percent Area T9',\n",
        "#        'Host Percent Area T10', 'Host Percent Area T11',\n",
        "#        'Host Percent Area T12', 'Host Percent Area T13',\n",
        "#        'Host Percent Area T14', 'Host Percent Area T15',\n",
        "#        'Host Percent Area T16', 'Host Percent Area T17',\n",
        "#        'Host Percent Area T18', 'Host Percent Area T19',\n",
        "#        'Host Percent Area T20', 'Host Percent Area T21',\n",
        "#        'Host Percent Area T22', 'Host Percent Area T23',\n",
        "#        'Host Percent Area T24', 'Host Percent Area T25',\n",
        "#        'Presence', 'phytosanitary_compliance', 'Probability of introduction',\n",
        "#        'Host Percent Area', 'AREA', 'Af', 'Am',\t'Aw',\t'BWh', 'BWk', 'BSh', 'BSk',\n",
        "#        'Csa',\t'Csb', 'Csc', 'Cwa', 'Cwb', 'Cwc', 'Cfa',\t'Cfb', 'Cfc',\t'Dsa',\n",
        "#        'Dsb',\t'Dsc', 'Dsd',\t'Dwa', 'Dwb',\t'Dwc', 'Dwd',\t'Dfa', 'Dfb',\t'Dfc',\n",
        "#        'Dfd',\t'ET', 'EF'], inplace = True)\n",
        "# check[['geometry', 'Probability of introduction T1', 'Presence T1']]\n",
        "check\n",
        "centroids = check.centroid.geometry\n",
        "# centroids = centroids.set_crs(epsg=4326)\n",
        "# centroids = centroids.to_crs(epsg=3857)\n",
        "# centroids = centroids.set_crs(epsg=3857)\n",
        "centroids = geopandas.GeoDataFrame(centroids)\n",
        "centroids = centroids.rename(columns={0: 'geometry'}).set_geometry('geometry')\n",
        "centroids[\"NAME\"] = check[\"NAME\"]\n",
        "centroids[\"title\"] = \"Spotted Lanternfly\"\n",
        "centroids[\"icon\"] = \"SLF\"\n",
        "\n",
        "# type(check)\n",
        "\n",
        "## write out yearly geojson\n",
        "for i in range(19):\n",
        "  col_name = 'Presence ' +str(i + start_year)\n",
        "  centroids[col_name] = check[col_name]\n",
        "  # col_name2 = 'Probability of introduction ' +str(i)\n",
        "  # c = check.loc[:,['geometry', col_name, col_name2]]\n",
        "  # cc = check.loc[check[col_name]].centroid\n",
        "  # c.to_file(outpath + \"pandemic_output\" + str(i + 1993) + \".geojson\", driver='GeoJSON')\n",
        "\n",
        "\n",
        "## write out yearly geojsons with both polygons and points in case we want to display the presence as an icon\n",
        "# for i in range(26):\n",
        "#   col_name = 'Presence ' +str(i + start_year)\n",
        "#   col_name2 = 'Probability of introduction ' +str(i + start_year)\n",
        "#   c = check.loc[:,['geometry', col_name2, 'NAME']]\n",
        "#   cc = check.centroid\n",
        "#   c.columns = ['geometry', 'Probability of introduction', 'NAME']\n",
        "#   cc['NAME'] = c['NAME'].values\n",
        "#   # cc.columns = ['geometry', 'Presence']\n",
        "#   c['Year'] = i + start_year\n",
        "#   # cc['Year'] = i + start_year\n",
        "#   if i == 0:\n",
        "#     pres_output = cc\n",
        "#     prob_output = c\n",
        "#   else:\n",
        "#     pres_output = pres_output.append(cc, ignore_index=True)\n",
        "#     prob_output = prob_output.append(c, ignore_index=True)\n",
        "\n",
        "  # c.to_file(outpath + \"pandemic_output_prob\" + str(i + 1993) + \".geojson\", driver='GeoJSON')\n",
        "  # cc.to_file(outpath + \"pandemic_output_pres\" + str(i + 1993) + \".geojson\", driver='GeoJSON')\n",
        "\n",
        "centroids\n",
        "# check.crs\n",
        "\n",
        "centroids.to_file(outpath + \"presence_pandemic.geojson\", driver='GeoJSON')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bn-bZ0iBkd62",
        "colab": {}
      },
      "source": [
        "prob_output\n",
        "import plotly.express as px\n",
        "fig = px.choropleth(prob_output, locations=\"NAME\", color=\"Probability of introduction\", hover_name=\"NAME\", animation_frame=\"Year\", range_color=[0,1])\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4vuTZE-twwQu",
        "colab": {}
      },
      "source": [
        "import plotly.express as px\n",
        "df = px.data.gapminder()\n",
        "fig = px.choropleth(df, locations=\"iso_alpha\", color=\"lifeExp\", hover_name=\"country\", animation_frame=\"year\", range_color=[20,80])\n",
        "# fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}