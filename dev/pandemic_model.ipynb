{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STATIC V1: SLF Pandemic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "python37_geo",
      "language": "python",
      "name": "python37_geo"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_C5c-iszeXFF"
      },
      "source": [
        "# **Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksSP31yFYDfA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "outputId": "64c46de4-e1ca-4a45-f810-b4d132ffe277"
      },
      "source": [
        "!pip install --upgrade geopandas\n",
        "!pip install --upgrade pyshp\n",
        "!pip install --upgrade shapely\n",
        "!pip install --upgrade descartes"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting geopandas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a4/e66aafbefcbb717813bf3a355c8c4fc3ed04ea1dd7feb2920f2f4f868921/geopandas-0.8.1-py2.py3-none-any.whl (962kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 7.3MB/s \n",
            "\u001b[?25hCollecting pyproj>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c3/071e080230ac4b6c64f1a2e2f9161c9737a2bc7b683d2c90b024825000c0/pyproj-2.6.1.post1-cp36-cp36m-manylinux2010_x86_64.whl (10.9MB)\n",
            "\u001b[K     |████████████████████████████████| 10.9MB 19.0MB/s \n",
            "\u001b[?25hCollecting fiona\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/20/4e63bc5c6e62df889297b382c3ccd4a7a488b00946aaaf81a118158c6f09/Fiona-1.8.13.post1-cp36-cp36m-manylinux1_x86_64.whl (14.7MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7MB 283kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: shapely in /usr/local/lib/python3.6/dist-packages (from geopandas) (1.7.1)\n",
            "Requirement already satisfied, skipping upgrade: click<8,>=4.0 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.7 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (1.15.0)\n",
            "Collecting munch\n",
            "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
            "Collecting cligj>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/be/30a58b4b0733850280d01f8bd132591b4668ed5c7046761098d665ac2174/cligj-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17 in /usr/local/lib/python3.6/dist-packages (from fiona->geopandas) (20.1.0)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->geopandas) (2.8.1)\n",
            "Installing collected packages: pyproj, munch, cligj, click-plugins, fiona, geopandas\n",
            "Successfully installed click-plugins-1.1.1 cligj-0.5.0 fiona-1.8.13.post1 geopandas-0.8.1 munch-2.5.0 pyproj-2.6.1.post1\n",
            "Collecting pyshp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/16/3bf15aa864fb77845fab8007eda22c2bd67bd6c1fd13496df452c8c43621/pyshp-2.1.0.tar.gz (215kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 8.4MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyshp\n",
            "  Building wheel for pyshp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyshp: filename=pyshp-2.1.0-cp36-none-any.whl size=32608 sha256=8853063cc6dc2ec5b20d24bba484681818a6562345bfbf02b5b218e4a61e6adc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/0c/de/321b5192ad416b328975a2f0385f72c64db4656501eba7cc1a\n",
            "Successfully built pyshp\n",
            "Installing collected packages: pyshp\n",
            "Successfully installed pyshp-2.1.0\n",
            "Requirement already up-to-date: shapely in /usr/local/lib/python3.6/dist-packages (1.7.1)\n",
            "Requirement already up-to-date: descartes in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from descartes) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->descartes) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->descartes) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->descartes) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->descartes) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->descartes) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->descartes) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fWmw4GRrWDA9",
        "colab": {}
      },
      "source": [
        "# Import necessary packages\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from scipy.spatial import distance\n",
        "import math\n",
        "import geopandas\n",
        "from shapely.geometry.polygon import Polygon\n",
        "from shapely.geometry.multipolygon import MultiPolygon\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Packages for use in CoLab\n",
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "536MsaaOeccI"
      },
      "source": [
        "# **Directory Path(s)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmRFVckYk-ct",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3cf0b828-2b87-4734-b1de-87f0410e5e5a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-NH4e9NRjYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_dir = 'G:/Shared drives/APHIS  Projects/Pandemic/Data/'\n",
        "data_dir = '/content/drive/Shared drives/APHIS  Projects/Pandemic/Data'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RUh53I7KefsH"
      },
      "source": [
        "# **Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LVDFV87sdru9",
        "colab": {}
      },
      "source": [
        "def climate_similarity(origin_climates, destination_climates):\n",
        "    \"\"\"\n",
        "    Returns the climate similarity between origin (i) and destion (j) by\n",
        "    simply checking whether or not the climate type is present in both the\n",
        "    origin (i) and destination (j) and summing the total area in the\n",
        "    destination (j) that is also in the origin (i).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    origin_climates : array (float)\n",
        "        An array with percent area for each of the Koppen climate zones for the\n",
        "        origin (i)\n",
        "    destination_climates : array (float)\n",
        "        An array with percent area for each of the Koppen climate zones for the\n",
        "        destination (j)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    similarity : float\n",
        "        What percentage of the total area of the origin country\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    similarity = 0.00\n",
        "    for clim in range(len(origin_climates)):\n",
        "        if origin_climates[clim] > 0 and destination_climates[clim] > 0:\n",
        "            similarity += destination_climates[clim]\n",
        "\n",
        "    return similarity"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Mu6KaRlyg_P",
        "colab": {}
      },
      "source": [
        "def distance_between(shapefile):\n",
        "    \"\"\"\n",
        "    Returns a n x n numpy array with the the distance from each element in a\n",
        "    shapefile to all other elements in that shapefile.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    shapefile : geodataframe\n",
        "        A geopandas dataframe of countries with crs(epsg = 4326)\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    distance : numpy array\n",
        "        An n x n numpy array of distances from each location to every other\n",
        "        location in kilometer\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    centroids = shapefile.centroid.geometry\n",
        "    centroids = centroids.to_crs(epsg=3395)\n",
        "    shapefile[\"centroid_lon\"] = centroids.x\n",
        "    shapefile[\"centroid_lat\"] = centroids.y\n",
        "    centroids_array = shapefile.loc[:, [\"centroid_lon\", \"centroid_lat\"]].values\n",
        "    distance_array = distance.cdist(\n",
        "        centroids_array, centroids_array,\"euclidean\"\n",
        "        )\n",
        "    distance_array = distance_array/1000\n",
        "    \n",
        "    return distance_array"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YpkOJc5NjMHc",
        "colab": {}
      },
      "source": [
        "def probability_of_entry(\n",
        "    rho_i, rho_j, zeta_it, lamda_c, T_ijct, sigma_T, mu, d_ij, chi_it\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of entry given trade volume, distance, and\n",
        "    capacity between two locations. We are thinking of locations as ports or\n",
        "    countries in which international trade happens.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rho_i : float\n",
        "        The phytosanitary capacity of origin (i)\n",
        "    rho_j : float\n",
        "        The phytosanitary capacity of destination (j)\n",
        "    zeta_it : bool\n",
        "        Species presence in origin (i) at time (t)\n",
        "    lamda_c : float\n",
        "        The commodity importance [0,1] of commodity (c) in transporting the\n",
        "        pest or pathogen\n",
        "    T_ijct : float\n",
        "        The trade volume between origin (i) and destination (j) for commodity\n",
        "        (c) at time (t) in metric tons\n",
        "    mu : float\n",
        "        The mortality rate of the pest or pathogen during transport\n",
        "    d_ij : int\n",
        "        the distance between origin (i) and destination (j)\n",
        "    chi_it : bool\n",
        "        The seasonality of the pest or pathogen in its ability to be in a\n",
        "        shipment\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_entry : float\n",
        "        The probability of a pest to enter the origin location\n",
        "\n",
        "    See Also\n",
        "    probability_of_establishment : Calculates the probability of establishment\n",
        "    probability_of_introduction : Calculates the probability of introduction\n",
        "        from the probability_of_establishment and probability_of_entry\n",
        "    \"\"\"\n",
        "\n",
        "    return (\n",
        "        (1 - rho_i)\n",
        "        * (1 - rho_j)\n",
        "        * zeta_it\n",
        "        * (1 - math.exp((-1) * lamda_c * (T_ijct / sigma_T)))\n",
        "        * math.exp((-1) * mu * d_ij)\n",
        "        * chi_it\n",
        "    )\n",
        "\n",
        "\n",
        "def probability_of_establishment(\n",
        "    alpha,\n",
        "    beta,\n",
        "    delta_kappa_ijt,\n",
        "    sigma_kappa,\n",
        "    h_jt,\n",
        "    sigma_h,\n",
        "    epsilon_jt,\n",
        "    sigma_epsilon,\n",
        "    phi,\n",
        "    sigma_phi,\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of establishment between origin (i) and destination\n",
        "    (j) given climate similarity between (i and j), host area in (j),\n",
        "    ecological distrubance in (j), and degree of polyphagy of the pest species.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha : float\n",
        "        A parameter that allows the equation to be adapated to various discrete\n",
        "        time steps\n",
        "    beta : float\n",
        "        A parameter that allows the equation to be adapted to various discrete\n",
        "        time steps\n",
        "    delta_kappa_ijt :float\n",
        "        The climate dissimilarity between the origin (i) and destination (j)\n",
        "        at time (t)\n",
        "    sigma_kappa : float\n",
        "        The climate dissimilarity normalizing constant\n",
        "    h_jt : float\n",
        "        The percent of area in the destination (j) that has suitable host for\n",
        "        the pest\n",
        "    sigma_h : float\n",
        "        The host normalizing constant\n",
        "    epsilon_jt : float\n",
        "        The ecological disturbance index of destination (j) at time (t)\n",
        "    sigma_epsilon : float\n",
        "        The ecological disturbance normalizing constant\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_phi : int\n",
        "        The degree of polyphagy normalizing constant\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_establishment : float\n",
        "        The probability of a pest to establish in the origin location\n",
        "\n",
        "    See Also\n",
        "    probability_of_entry : Calculates the probability of entry\n",
        "    probability_of_introduction : Calculates the probability of introduction\n",
        "        from the probability_of_establishment and probability_of_entry\n",
        "    \"\"\"\n",
        "\n",
        "    return alpha * math.exp(\n",
        "        (-1)\n",
        "        * beta\n",
        "        * (\n",
        "            ((1 - delta_kappa_ijt) / sigma_kappa) ** 2\n",
        "            + ((1 - h_jt) / sigma_h) ** 2\n",
        "            + ((1 - epsilon_jt) / sigma_epsilon) ** 2\n",
        "            + (phi / sigma_phi) ** (-2)\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "def probability_of_introduction(\n",
        "    probability_of_entry_ijct, probability_of_establishment_ijt\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of introduction given a vector of\n",
        "    probability_of_entry between origin (i) and destination (j) at time t\n",
        "    with c commodities and a probability_of_establishment between origin (i)\n",
        "    and destination (j)\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    probability_of_entry_ijct : float\n",
        "        The probability of a pest entering destination (j) from origin (i) on\n",
        "        commodity (c) at time (t)\n",
        "    probability_of_establishment_ijt : float\n",
        "        The probability of a pest establishing in destination (j) coming from\n",
        "        origin (i) at time (t)\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_introduction : float\n",
        "        The probability of a pest being introduced in the origin (i) location\n",
        "        from destination j\n",
        "\n",
        "    See Also\n",
        "    probability_of_entry : Calculates the probability of entry\n",
        "    probability_of_establishment : Calculates the probability of establishment\n",
        "    \"\"\"\n",
        "\n",
        "    return probability_of_entry_ijct * probability_of_establishment_ijt\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wu6__Q8-jeqf",
        "colab": {}
      },
      "source": [
        "def pandemic(\n",
        "    trade,\n",
        "    distances,\n",
        "    locations,\n",
        "    alpha,\n",
        "    beta,\n",
        "    mu,\n",
        "    lamda_c,\n",
        "    phi,\n",
        "    sigma_epsilon,\n",
        "    sigma_h,\n",
        "    sigma_kappa,\n",
        "    sigma_phi,\n",
        "    sigma_T,\n",
        "    time_step\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of establishment, probability of entry, and\n",
        "    probability of introduction as an n x n matrices between every origin (i)\n",
        "    and destination (j) and update species presence and the combined\n",
        "    probability of presence for each origin (i) given climate similarity\n",
        "    between (i and j), host area in (j), ecological distrubance in (j), degree\n",
        "    of polyphagy of the pest species, trade volumes, distance, and\n",
        "    phytosanitary capacity.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    locations : data_frame\n",
        "        data frame of countries, species presence, phytosanitry capacity,\n",
        "        koppen climate classifications % of total area for each class.\n",
        "    trade : numpy.array\n",
        "        list (c) of n x n x t matrices where c is the # of commoditites,\n",
        "        n is the number of locations, and t is # of time steps\n",
        "    distances : numpy.array\n",
        "        n x n matrix of distances from one location to another where n is\n",
        "        number of locations.\n",
        "    alpha : float\n",
        "        A parameter that allows the equation to be adapated to various discrete\n",
        "        time steps\n",
        "    beta : float\n",
        "        A parameter that allows the equation to be adapted to various discrete\n",
        "        time steps\n",
        "    mu : float\n",
        "        The mortality rate of the pest or pathogen during transport\n",
        "    lamda_c : float\n",
        "        The commodity importance [0,1] of commodity (c) in transporting the\n",
        "        pest or pathogen\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_kappa : float\n",
        "        The climate dissimilarity normalizing constant\n",
        "    sigma_h : float\n",
        "        The host normalizing constant\n",
        "    sigma_epsilon : float\n",
        "        The ecological disturbance normalizing constant\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_phi : int\n",
        "        The degree of polyphagy normalizing constant\n",
        "    sigma_T : int\n",
        "        The trade volume normalizing constant\n",
        "    time_step: str\n",
        "      The year-month combination of the time step\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_establishment : float\n",
        "        The probability of a pest to establish in the origin location\n",
        "\n",
        "    See Also\n",
        "    probability_of_entry : Calculates the probability of entry\n",
        "    probability_of_introduction : Calculates the probability of introduction\n",
        "        from the probability_of_establishment and probability_of_entry\n",
        "    \"\"\"\n",
        "\n",
        "    entry_probabilities = np.empty_like(trade, dtype=float)\n",
        "    establishment_probabilities = np.empty_like(trade, dtype=float)\n",
        "    introduction_probabilities = np.empty_like(trade, dtype=float)\n",
        "    \n",
        "    introduction_country = np.empty_like(trade, dtype=float)\n",
        "    locations[\"Probability of introduction\"] = np.empty(len(locations))\n",
        "    origin_destination = pd.DataFrame(columns=['Origin', 'Destination'])\n",
        "\n",
        "    \n",
        "    for j in range(len(locations)):\n",
        "        destination = locations.iloc[j, :]\n",
        "        combined_probability_no_introduction = 1\n",
        "    \n",
        "        # check that Phytosanitary capacity data is available if not set\n",
        "        # the value to 0 to remove this aspect of the equation\n",
        "        if \"Phytosanitary Capacity\" in destination:\n",
        "            rho_j = destination[\"Phytosanitary Capacity\"]\n",
        "        else:\n",
        "            rho_j = 0\n",
        "\n",
        "        for i in range(len(locations)):\n",
        "            origin = locations.iloc[i, :]\n",
        "            \n",
        "            # check that Phytosanitary capacity data is available if not\n",
        "            # set value to 0 to remove this aspect of the equation\n",
        "            if \"Phytosanitary Capacity\" in origin:\n",
        "                rho_i = origin[\"Phytosanitary Capacity\"] \n",
        "            else:\n",
        "                rho_i = 0\n",
        "\n",
        "\n",
        "            T_ijct = trade[j, i]\n",
        "            d_ij = distances[j, i]\n",
        "            \n",
        "            # TO DO: Need to generalize -- this is for SLF \n",
        "            # Northern Hemisphere & Fall/Winter Months\n",
        "            if (origin['centroid_lat'] >= 0 and time_step[-2:] in\n",
        "                    ['09', '10', '11', '12', '01', '02', '03', '04']):\n",
        "                chi_it = 1\n",
        "            # Southern Hemisphere & Fall/Winter Months\n",
        "            elif (origin['centroid_lat'] < 0 and time_step[-2:] in\n",
        "                      ['04', '05', '06', '07', '08', '09', '10']):\n",
        "                chi_it = 1\n",
        "            else:\n",
        "                chi_it = 0\n",
        "                \n",
        "            h_jt = destination[\"Host Percent Area\"]\n",
        "            \n",
        "            if origin[\"Presence\"] and h_jt > 0:\n",
        "                zeta_it = int(origin[\"Presence\"])\n",
        "\n",
        "                origin_climates = origin.loc[['Af', 'Am',\t'Aw',\t'BWh', 'BWk', \n",
        "                                              'BSh', 'BSk', 'Csa',\t'Csb', \n",
        "                                              'Csc', 'Cwa', 'Cwb', 'Cwc', \n",
        "                                              'Cfa',\t'Cfb', 'Cfc',\t'Dsa', \n",
        "                                              'Dsb',\t'Dsc', 'Dsd',\t'Dwa', \n",
        "                                              'Dwb',\t'Dwc', 'Dwd',\t'Dfa', \n",
        "                                              'Dfb',\t'Dfc', 'Dfd',\t'ET', 'EF']]\n",
        "\n",
        "                destination_climates = destination.loc[['Af', 'Am',\t'Aw',\t\n",
        "                                                        'BWh', 'BWk', 'BSh',\n",
        "                                                        'BSk', 'Csa',\t'Csb',\n",
        "                                                        'Csc', 'Cwa', 'Cwb',\n",
        "                                                        'Cwc', 'Cfa',\t'Cfb',\n",
        "                                                        'Cfc',\t'Dsa', 'Dsb',\n",
        "                                                        'Dsc', 'Dsd',\t'Dwa', \n",
        "                                                        'Dwb',\t'Dwc', 'Dwd',\n",
        "                                                        'Dfa', 'Dfb',\t'Dfc',\n",
        "                                                        'Dfd',\t'ET', 'EF']]\n",
        "                \n",
        "                delta_kappa_ijt = climate_similarity(\n",
        "                    origin_climates, destination_climates)\n",
        "\n",
        "                if \"Ecological Disturbance\" in origin:\n",
        "                    epsilon_jt = origin[\"Ecological Disturbance\"]\n",
        "                else:\n",
        "                    epsilon_jt = 0\n",
        "\n",
        "                \n",
        "                probability_of_entry_ijct = probability_of_entry(\n",
        "                    rho_i, rho_j, zeta_it, lamda_c, T_ijct, \n",
        "                    sigma_T, mu, d_ij, chi_it\n",
        "                )\n",
        "                \n",
        "                probability_of_establishment_ijt = probability_of_establishment(\n",
        "                    alpha,\n",
        "                    beta,\n",
        "                    delta_kappa_ijt,\n",
        "                    sigma_kappa,\n",
        "                    h_jt,\n",
        "                    sigma_h,\n",
        "                    epsilon_jt,\n",
        "                    sigma_epsilon,\n",
        "                    phi,\n",
        "                    sigma_phi,\n",
        "                )\n",
        "            \n",
        "            else:\n",
        "                zeta_it = 0\n",
        "                probability_of_entry_ijct = 0.0\n",
        "                probability_of_establishment_ijt = 0.0\n",
        "\n",
        "            probability_of_introduction_ijtc = probability_of_introduction(\n",
        "                probability_of_entry_ijct, probability_of_establishment_ijt\n",
        "            )\n",
        "            \n",
        "            entry_probabilities[j, i] = probability_of_entry_ijct\n",
        "            establishment_probabilities[j, i] = probability_of_establishment_ijt\n",
        "            introduction_probabilities[j, i] = probability_of_introduction_ijtc\n",
        "            \n",
        "            # decide if an introduction happens\n",
        "            introduced = np.random.binomial(1, probability_of_introduction_ijtc)\n",
        "            combined_probability_no_introduction = (\n",
        "                combined_probability_no_introduction * \n",
        "                (1 - probability_of_introduction_ijtc)\n",
        "            )\n",
        "            \n",
        "            if bool(introduced):\n",
        "                introduction_country[j, i] = bool(introduced)\n",
        "                locations.iloc[j, locations.columns.get_loc(\"Presence\")] = (\n",
        "                    bool(introduced)\n",
        "                )\n",
        "                print('\\t', origin['NAME'], '-->', destination['NAME'])\n",
        "                \n",
        "                if origin_destination.empty:\n",
        "                    origin_destination = pd.DataFrame([[origin['NAME'], \n",
        "                                                        destination['NAME']]], \n",
        "                                                      columns=['Origin', \n",
        "                                                               'Destination']\n",
        "                                                      )\n",
        "                else:\n",
        "                    origin_destination = (origin_destination.append(\n",
        "                        pd.DataFrame([[origin['NAME'],\n",
        "                                       destination['NAME']]],\n",
        "                                     columns=['Origin', 'Destination']),\n",
        "                                     ignore_index=True)\n",
        "                    )\n",
        "            else:\n",
        "                introduction_country[j, i] = bool(introduced)\n",
        "\n",
        "        locations.iloc[j, locations.columns.get_loc(\"Probability of introduction\")] = 1 - combined_probability_no_introduction\n",
        "\n",
        "    return (\n",
        "        entry_probabilities, \n",
        "        establishment_probabilities, \n",
        "        introduction_probabilities, \n",
        "        introduction_country, \n",
        "        locations, \n",
        "        origin_destination\n",
        "    )\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ncBoqSTApVIR",
        "colab": {}
      },
      "source": [
        "def pandemic2(\n",
        "    trades,\n",
        "    distances,\n",
        "    locations,\n",
        "    alpha,\n",
        "    beta,\n",
        "    mu,\n",
        "    lamda_c,\n",
        "    phi,\n",
        "    sigma_epsilon,\n",
        "    sigma_h,\n",
        "    sigma_kappa,\n",
        "    sigma_phi,\n",
        "    sigma_T,\n",
        "    start_year,\n",
        "    random_seed = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns the probability of establishment, probability of entry, and\n",
        "    probability of introduction as an n x n matrices betweem every origin (i)\n",
        "    and destination (j) and update species presence and the combined\n",
        "    probability of presence for each origin (i) given climate similarity\n",
        "    between (i and j), host area in (j), ecological distrubance in (j), degree\n",
        "    of polyphagy of the pest species, trade volumes, distance, and\n",
        "    phytosanitary capacity.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    locations : data_frame\n",
        "        data frame of countries, species presence, phytosanitry capacity,\n",
        "        koppen climate classifications % of total area for each class.\n",
        "    trades : numpy.array\n",
        "        list (c) of n x n x t matrices where c is the # of commoditites,\n",
        "        n is the number of locations, and t is # of time steps\n",
        "    distances : numpy.array\n",
        "        n x n matrix of distances from one location to another where n is\n",
        "        number of locations.\n",
        "    alpha : float\n",
        "        A parameter that allows the equation to be adapated to various discrete\n",
        "        time steps\n",
        "    beta : float\n",
        "        A parameter that allows the equation to be adapted to various discrete\n",
        "        time steps\n",
        "    mu : float\n",
        "        The mortality rate of the pest or pathogen during transport\n",
        "    lamda_c : float\n",
        "        The commodity importance [0,1] of commodity (c) in transporting the\n",
        "        pest or pathogen\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_kappa : float\n",
        "        The climate dissimilarity normalizing constant\n",
        "    sigma_h : float\n",
        "        The host normalizing constant\n",
        "    sigma_epsilon : float\n",
        "        The ecological disturbance normalizing constant\n",
        "    phi : int\n",
        "        The degree of polyphagy of the pest of interest described as the number\n",
        "        of host families\n",
        "    sigma_phi : int\n",
        "        The degree of polyphagy normalizing constant\n",
        "    sigma_T : int\n",
        "        The trade volume normalizing constant\n",
        "    start_year : int\n",
        "        The year in which to start the simulation\n",
        "    random_seed : int (optional)\n",
        "        The number to use for initializing random values. If not provided, a new\n",
        "        value will be used for every simulation and results may differ for the\n",
        "        same input data and function parameters. If provided, the results of a\n",
        "        simulation can be reproduced.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    probability_of_establishment : float\n",
        "        The probability of a pest to establish in the origin location\n",
        "\n",
        "    See Also\n",
        "    probability_of_entry : Calculates the probability of entry\n",
        "    probability_of_introduction : Calculates the probability of introduction\n",
        "        from the probability_of_establishment and probability_of_entry\n",
        "    \"\"\"\n",
        "\n",
        "    time_steps = trades.shape[0]\n",
        "    \n",
        "    entry_probabilities = np.empty_like(trades, dtype=float)\n",
        "    establishment_probabilities = np.empty_like(trades, dtype=float)\n",
        "    introduction_probabilities = np.empty_like(trades, dtype=float)\n",
        "    \n",
        "    introduction_countries = np.empty_like(trades, dtype=float)\n",
        "    locations[\"Probability of introduction\"] = np.zeros(shape=len(locations))\n",
        "    origin_destination = pd.DataFrame(columns=['Origin', 'Destination', 'Year'])\n",
        "    \n",
        "    date_list = pd.date_range(f'{str(start_year)}-01', \n",
        "                              f'{str(start_year + int(time_steps/12)-1)}-12', \n",
        "                              freq='MS').strftime(\"%Y%m\").tolist()\n",
        "    \n",
        "    for t in range(trades.shape[0]):\n",
        "        ts = date_list[t]\n",
        "        print('TIME STEP: ', ts)\n",
        "        trade = trades[t]\n",
        "        \n",
        "        ##TO DO: generalize for changing host percent area, static phytosanitary capacity, etc\n",
        "        locations[\"Host Percent Area\"] = locations[\"Host Percent Area\"]\n",
        "        # if locations[\"Host Percent Area T\" + str(t)] in locations.columns:\n",
        "        #   locations[\"Host Percent Area\"] = locations[\"Host Percent Area T\" + str(t)]\n",
        "        # else:\n",
        "        #   locations[\"Host Percent Area\"] = locations[\"Host Percent Area\"]\n",
        "        locations[\"Presence \" + str(ts)] = locations['Presence']\n",
        "        locations[\"Probability of introduction \"  + str(ts)] = locations[\"Probability of introduction\"]\n",
        "        locations[\"Phytosanitary Capacity\"] = locations ['Phytosanitary Capacity ' + ts[:4]]\n",
        "\n",
        "        ts_out = pandemic(\n",
        "        trade=trade,\n",
        "        distances=distances,\n",
        "        locations=locations,\n",
        "        alpha=alpha,\n",
        "        beta=beta,\n",
        "        mu=mu,\n",
        "        lamda_c=lamda_c,\n",
        "        phi=phi,\n",
        "        sigma_epsilon=sigma_epsilon,\n",
        "        sigma_h=sigma_h,\n",
        "        sigma_kappa=sigma_kappa,\n",
        "        sigma_phi=sigma_phi,\n",
        "        sigma_T=sigma_T,\n",
        "        time_step=ts)\n",
        "\n",
        "        establishment_probabilities[t] = ts_out[1]\n",
        "        entry_probabilities[t] = ts_out[0]\n",
        "        introduction_probabilities[t] = ts_out[2]\n",
        "        introduction_countries[t] = ts_out[3]\n",
        "        locations = ts_out[4]\n",
        "        origin_destination_ts = ts_out[5]\n",
        "        origin_destination_ts['TS'] = ts\n",
        "        if origin_destination.empty:\n",
        "            origin_destination = origin_destination_ts\n",
        "        else:\n",
        "            origin_destination = origin_destination.append(origin_destination_ts, ignore_index=True)\n",
        "\n",
        "    locations[\"Presence \" + str(ts)] = locations[\"Presence\"]\n",
        "    locations[\"Probability of introduction \"  + str(ts)] = locations[\"Probability of introduction\"]\n",
        "\n",
        "    return (\n",
        "        locations, \n",
        "        entry_probabilities, \n",
        "        establishment_probabilities, \n",
        "        introduction_probabilities, \n",
        "        origin_destination, \n",
        "        introduction_countries, \n",
        "        date_list\n",
        "    )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zk5H1aSHemXY"
      },
      "source": [
        "# **Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MoXOUa_qRTR7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9e10922-69af-4df3-9887-4e19ce20b466"
      },
      "source": [
        "countries = geopandas.read_file(data_dir + '/slf_model/inputs/countries4.gpkg', driver = 'GPKG')\n",
        "countries.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(236, 38)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E8HXw_mLnHpK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "de1e88a7-5a8e-4e44-dd5c-c85f52676ed1"
      },
      "source": [
        "# get distance n x n matrix\n",
        "distances = distance_between(countries)\n",
        "print(f'countries: {countries.shape}\\tdistances: {distances.shape}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "countries: (236, 38)\tdistances: (236, 236)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2NtTQgGRjZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "19ae690b-5386-400b-b949-d540bec3b257"
      },
      "source": [
        "gdp = pd.read_csv(data_dir \n",
        "                  + '/GDP/2000_2019_GDP_perCapita/gdp_perCapita_binned.csv', \n",
        "                  index_col =0)\n",
        "gdp['pc_mode'] = gdp[['2000', '2001', '2002', '2003', '2004',\n",
        "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
        "       '2014', '2015', '2016', '2017', '2018', '2019']].mode(axis=1)[0]\n",
        "year_cols = gdp.columns[3:-1]\n",
        "gdp.columns = np.where(\n",
        "    gdp.columns.isin(year_cols),\n",
        "    'Phytosanitary Capacity ' + gdp.columns,\n",
        "     gdp.columns\n",
        "     )\n",
        "gdp.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>Country Code</th>\n",
              "      <th>Phytosanitary Capacity 2000</th>\n",
              "      <th>Phytosanitary Capacity 2001</th>\n",
              "      <th>Phytosanitary Capacity 2002</th>\n",
              "      <th>Phytosanitary Capacity 2003</th>\n",
              "      <th>Phytosanitary Capacity 2004</th>\n",
              "      <th>Phytosanitary Capacity 2005</th>\n",
              "      <th>Phytosanitary Capacity 2006</th>\n",
              "      <th>Phytosanitary Capacity 2007</th>\n",
              "      <th>Phytosanitary Capacity 2008</th>\n",
              "      <th>Phytosanitary Capacity 2009</th>\n",
              "      <th>Phytosanitary Capacity 2010</th>\n",
              "      <th>Phytosanitary Capacity 2011</th>\n",
              "      <th>Phytosanitary Capacity 2012</th>\n",
              "      <th>Phytosanitary Capacity 2013</th>\n",
              "      <th>Phytosanitary Capacity 2014</th>\n",
              "      <th>Phytosanitary Capacity 2015</th>\n",
              "      <th>Phytosanitary Capacity 2016</th>\n",
              "      <th>Phytosanitary Capacity 2017</th>\n",
              "      <th>Phytosanitary Capacity 2018</th>\n",
              "      <th>Phytosanitary Capacity 2019</th>\n",
              "      <th>pc_mode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>533</td>\n",
              "      <td>Aruba</td>\n",
              "      <td>ABW</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>AFG</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>24</td>\n",
              "      <td>Angola</td>\n",
              "      <td>AGO</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>Albania</td>\n",
              "      <td>ALB</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>20</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>AND</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    UN         NAME  ... Phytosanitary Capacity 2019 pc_mode\n",
              "1  533        Aruba  ...                         NaN     low\n",
              "2    4  Afghanistan  ...                         low     low\n",
              "3   24       Angola  ...                         low     low\n",
              "4    8      Albania  ...                         low     low\n",
              "5   20      Andorra  ...                         mid     mid\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3BR9HGARjZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "c10833e1-1036-4e9f-c357-9cc25f74709f"
      },
      "source": [
        "countries = countries.merge(gdp, how='left', on='UN', suffixes = [None, '_y'])\n",
        "countries.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>AREA_x</th>\n",
              "      <th>centroid_lon</th>\n",
              "      <th>centroid_lat</th>\n",
              "      <th>Af</th>\n",
              "      <th>Am</th>\n",
              "      <th>Aw</th>\n",
              "      <th>BWh</th>\n",
              "      <th>BWk</th>\n",
              "      <th>BSh</th>\n",
              "      <th>BSk</th>\n",
              "      <th>Csa</th>\n",
              "      <th>Csb</th>\n",
              "      <th>Csc</th>\n",
              "      <th>Cwa</th>\n",
              "      <th>Cwb</th>\n",
              "      <th>Cwc</th>\n",
              "      <th>Cfa</th>\n",
              "      <th>Cfb</th>\n",
              "      <th>Cfc</th>\n",
              "      <th>Dsa</th>\n",
              "      <th>Dsb</th>\n",
              "      <th>Dsc</th>\n",
              "      <th>Dsd</th>\n",
              "      <th>Dwa</th>\n",
              "      <th>Dwb</th>\n",
              "      <th>Dwc</th>\n",
              "      <th>Dwd</th>\n",
              "      <th>Dfa</th>\n",
              "      <th>Dfb</th>\n",
              "      <th>Dfc</th>\n",
              "      <th>Dfd</th>\n",
              "      <th>ET</th>\n",
              "      <th>EF</th>\n",
              "      <th>Host Percent Area</th>\n",
              "      <th>AREA</th>\n",
              "      <th>geometry</th>\n",
              "      <th>NAME_y</th>\n",
              "      <th>Country Code</th>\n",
              "      <th>Phytosanitary Capacity 2000</th>\n",
              "      <th>Phytosanitary Capacity 2001</th>\n",
              "      <th>Phytosanitary Capacity 2002</th>\n",
              "      <th>Phytosanitary Capacity 2003</th>\n",
              "      <th>Phytosanitary Capacity 2004</th>\n",
              "      <th>Phytosanitary Capacity 2005</th>\n",
              "      <th>Phytosanitary Capacity 2006</th>\n",
              "      <th>Phytosanitary Capacity 2007</th>\n",
              "      <th>Phytosanitary Capacity 2008</th>\n",
              "      <th>Phytosanitary Capacity 2009</th>\n",
              "      <th>Phytosanitary Capacity 2010</th>\n",
              "      <th>Phytosanitary Capacity 2011</th>\n",
              "      <th>Phytosanitary Capacity 2012</th>\n",
              "      <th>Phytosanitary Capacity 2013</th>\n",
              "      <th>Phytosanitary Capacity 2014</th>\n",
              "      <th>Phytosanitary Capacity 2015</th>\n",
              "      <th>Phytosanitary Capacity 2016</th>\n",
              "      <th>Phytosanitary Capacity 2017</th>\n",
              "      <th>Phytosanitary Capacity 2018</th>\n",
              "      <th>Phytosanitary Capacity 2019</th>\n",
              "      <th>pc_mode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>65209</td>\n",
              "      <td>7.350040e+06</td>\n",
              "      <td>3.983398e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.268111</td>\n",
              "      <td>0.028333</td>\n",
              "      <td>0.019333</td>\n",
              "      <td>0.321889</td>\n",
              "      <td>0.031778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070444</td>\n",
              "      <td>0.124000</td>\n",
              "      <td>0.092</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.119000</td>\n",
              "      <td>9.346711e+07</td>\n",
              "      <td>POLYGON ((74.91574 37.23733, 74.83221 37.22041...</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>AFG</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2740</td>\n",
              "      <td>2.234000e+06</td>\n",
              "      <td>5.005271e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380631</td>\n",
              "      <td>0.114865</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157658</td>\n",
              "      <td>0.054054</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065315</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.211712</td>\n",
              "      <td>0.015766</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.934685</td>\n",
              "      <td>5.062603e+06</td>\n",
              "      <td>POLYGON ((19.43621 41.02107, 19.45055 41.06000...</td>\n",
              "      <td>Albania</td>\n",
              "      <td>ALB</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>238174</td>\n",
              "      <td>2.930336e+05</td>\n",
              "      <td>3.249422e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.875809</td>\n",
              "      <td>0.044779</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>0.043934</td>\n",
              "      <td>0.034438</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.060518</td>\n",
              "      <td>3.014479e+08</td>\n",
              "      <td>POLYGON ((2.96361 36.80222, 2.98139 36.80694, ...</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>DZA</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>American Samoa</td>\n",
              "      <td>20</td>\n",
              "      <td>-1.896905e+07</td>\n",
              "      <td>-1.596503e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.460787e+04</td>\n",
              "      <td>MULTIPOLYGON (((-169.44449 -14.26167, -169.509...</td>\n",
              "      <td>American Samoa</td>\n",
              "      <td>ASM</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>low</td>\n",
              "      <td>NaN</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>0</td>\n",
              "      <td>1.754048e+05</td>\n",
              "      <td>5.214610e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>9.388807e+04</td>\n",
              "      <td>POLYGON ((1.78172 42.56996, 1.77472 42.57111, ...</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>AND</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "      <td>mid</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UN            NAME  ...  Phytosanitary Capacity 2019  pc_mode\n",
              "0   4     Afghanistan  ...                          low      low\n",
              "1   8         Albania  ...                          low      low\n",
              "2  12         Algeria  ...                          low      low\n",
              "3  16  American Samoa  ...                          NaN      low\n",
              "4  20         Andorra  ...                          mid      mid\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5rm4kwTRjZ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "0b1ec282-95e2-41c4-e0d1-4906d906c4fc"
      },
      "source": [
        "gdp_dict = {'low': .25,\n",
        "            'mid': .7,\n",
        "            'high': .9,\n",
        "            np.nan: 0}\n",
        "countries.replace(gdp_dict,\n",
        "                  inplace=True)\n",
        "countries.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>AREA_x</th>\n",
              "      <th>centroid_lon</th>\n",
              "      <th>centroid_lat</th>\n",
              "      <th>Af</th>\n",
              "      <th>Am</th>\n",
              "      <th>Aw</th>\n",
              "      <th>BWh</th>\n",
              "      <th>BWk</th>\n",
              "      <th>BSh</th>\n",
              "      <th>BSk</th>\n",
              "      <th>Csa</th>\n",
              "      <th>Csb</th>\n",
              "      <th>Csc</th>\n",
              "      <th>Cwa</th>\n",
              "      <th>Cwb</th>\n",
              "      <th>Cwc</th>\n",
              "      <th>Cfa</th>\n",
              "      <th>Cfb</th>\n",
              "      <th>Cfc</th>\n",
              "      <th>Dsa</th>\n",
              "      <th>Dsb</th>\n",
              "      <th>Dsc</th>\n",
              "      <th>Dsd</th>\n",
              "      <th>Dwa</th>\n",
              "      <th>Dwb</th>\n",
              "      <th>Dwc</th>\n",
              "      <th>Dwd</th>\n",
              "      <th>Dfa</th>\n",
              "      <th>Dfb</th>\n",
              "      <th>Dfc</th>\n",
              "      <th>Dfd</th>\n",
              "      <th>ET</th>\n",
              "      <th>EF</th>\n",
              "      <th>Host Percent Area</th>\n",
              "      <th>AREA</th>\n",
              "      <th>geometry</th>\n",
              "      <th>NAME_y</th>\n",
              "      <th>Country Code</th>\n",
              "      <th>Phytosanitary Capacity 2000</th>\n",
              "      <th>Phytosanitary Capacity 2001</th>\n",
              "      <th>Phytosanitary Capacity 2002</th>\n",
              "      <th>Phytosanitary Capacity 2003</th>\n",
              "      <th>Phytosanitary Capacity 2004</th>\n",
              "      <th>Phytosanitary Capacity 2005</th>\n",
              "      <th>Phytosanitary Capacity 2006</th>\n",
              "      <th>Phytosanitary Capacity 2007</th>\n",
              "      <th>Phytosanitary Capacity 2008</th>\n",
              "      <th>Phytosanitary Capacity 2009</th>\n",
              "      <th>Phytosanitary Capacity 2010</th>\n",
              "      <th>Phytosanitary Capacity 2011</th>\n",
              "      <th>Phytosanitary Capacity 2012</th>\n",
              "      <th>Phytosanitary Capacity 2013</th>\n",
              "      <th>Phytosanitary Capacity 2014</th>\n",
              "      <th>Phytosanitary Capacity 2015</th>\n",
              "      <th>Phytosanitary Capacity 2016</th>\n",
              "      <th>Phytosanitary Capacity 2017</th>\n",
              "      <th>Phytosanitary Capacity 2018</th>\n",
              "      <th>Phytosanitary Capacity 2019</th>\n",
              "      <th>pc_mode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>65209</td>\n",
              "      <td>7.350040e+06</td>\n",
              "      <td>3.983398e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.268111</td>\n",
              "      <td>0.028333</td>\n",
              "      <td>0.019333</td>\n",
              "      <td>0.321889</td>\n",
              "      <td>0.031778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.070444</td>\n",
              "      <td>0.124000</td>\n",
              "      <td>0.092</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.119000</td>\n",
              "      <td>9.346711e+07</td>\n",
              "      <td>POLYGON ((74.91574 37.23733, 74.83221 37.22041...</td>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>AFG</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>Albania</td>\n",
              "      <td>2740</td>\n",
              "      <td>2.234000e+06</td>\n",
              "      <td>5.005271e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.380631</td>\n",
              "      <td>0.114865</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.157658</td>\n",
              "      <td>0.054054</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065315</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.211712</td>\n",
              "      <td>0.015766</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.934685</td>\n",
              "      <td>5.062603e+06</td>\n",
              "      <td>POLYGON ((19.43621 41.02107, 19.45055 41.06000...</td>\n",
              "      <td>Albania</td>\n",
              "      <td>ALB</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>238174</td>\n",
              "      <td>2.930336e+05</td>\n",
              "      <td>3.249422e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.875809</td>\n",
              "      <td>0.044779</td>\n",
              "      <td>0.000911</td>\n",
              "      <td>0.043934</td>\n",
              "      <td>0.034438</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.060518</td>\n",
              "      <td>3.014479e+08</td>\n",
              "      <td>POLYGON ((2.96361 36.80222, 2.98139 36.80694, ...</td>\n",
              "      <td>Algeria</td>\n",
              "      <td>DZA</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>American Samoa</td>\n",
              "      <td>20</td>\n",
              "      <td>-1.896905e+07</td>\n",
              "      <td>-1.596503e+06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.460787e+04</td>\n",
              "      <td>MULTIPOLYGON (((-169.44449 -14.26167, -169.509...</td>\n",
              "      <td>American Samoa</td>\n",
              "      <td>ASM</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>0</td>\n",
              "      <td>1.754048e+05</td>\n",
              "      <td>5.214610e+06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>9.388807e+04</td>\n",
              "      <td>POLYGON ((1.78172 42.56996, 1.77472 42.57111, ...</td>\n",
              "      <td>Andorra</td>\n",
              "      <td>AND</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UN            NAME  ...  Phytosanitary Capacity 2019  pc_mode\n",
              "0   4     Afghanistan  ...                         0.25     0.25\n",
              "1   8         Albania  ...                         0.25     0.25\n",
              "2  12         Algeria  ...                         0.25     0.25\n",
              "3  16  American Samoa  ...                         0.00     0.25\n",
              "4  20         Andorra  ...                         0.70     0.70\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fz9yQAm0yG-j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96b92f8b-587a-447f-8e88-ff8d246e68ed"
      },
      "source": [
        "## path to directory  \n",
        "#directory_path = \"/content/drive/Shared drives/APHIS  Projects/Pandemic/Data/slf_model/inputs/annual/all_commodities/*.csv\" #codes 6801 - 6815\n",
        "#directory_path = \"/content/drive/Shared drives/APHIS  Projects/Pandemic/Data/slf_model/inputs/annual/select_stone/*.csv\" #codes 6801-6804\n",
        "directory_path = data_dir + \"/slf_model/inputs/monthly/select_commodities/*.csv\" #codes 6801-6804\n",
        "file_list_historical = glob.glob(directory_path)\n",
        "file_list_historical.sort()\n",
        "\n",
        "file_list_forecast = glob.glob(data_dir + \n",
        "                               '/slf_model/inputs/monthly/forecast/static/*.csv')\n",
        "file_list_forecast.sort()\n",
        "\n",
        "file_list = file_list_historical #+ file_list_forecast\n",
        "\n",
        "trades = np.zeros(shape = (len(file_list), \n",
        "                           distances.shape[0], \n",
        "                           distances.shape[0]))\n",
        "for i in range(len(file_list)):\n",
        "    trades[i] = pd.read_csv(file_list[i], \n",
        "                            sep = \",\", \n",
        "                            header= 0, \n",
        "                            index_col=0, \n",
        "                            encoding='latin1').values\n",
        "\n",
        "traded = pd.read_csv(file_list[1], \n",
        "                     sep = \",\",\n",
        "                     header= 0, \n",
        "                     index_col=0, \n",
        "                     encoding='latin1')\n",
        "trades.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(228, 236, 236)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aNKviMY3Y5nX",
        "colab": {}
      },
      "source": [
        "#Native range to start presence = True at T0\n",
        "china_index = countries.index[countries['NAME'] == 'China'][0]\n",
        "viet_nam_index = countries.index[countries['NAME'] == 'Viet Nam'][0]\n",
        "india_index = countries.index[countries['NAME'] == 'India'][0]\n",
        "native_countries_list = ['China', 'Viet Nam', 'India']\n",
        "\n",
        "#Known Introductions \n",
        "skorea_index = countries.index[countries['NAME'] == 'Korea, Republic of'][0]\n",
        "japan_index = countries.index[countries['NAME'] == 'Japan'][0]\n",
        "us_index = countries.index[countries['NAME'] == 'United States'][0]\n",
        "known_introductions_list = ['United States', 'Korea, Republic of', 'Japan']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I-SqkRkEesvc"
      },
      "source": [
        "# **Model Parameters & Runs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl7J_6NdRjad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### notes on numbers used and rationale\n",
        "## Parameters that should be calibrated and validated as much as possible\n",
        "# alpha - just choose these as starting values\n",
        "# beta - just choose these as starting values\n",
        "# mu - just choose these as starting values\n",
        "\n",
        "## Parameters that we can set based on underlying data to normalize\n",
        "# sigma_h = 1 - the mean of the host percent area (not sure that this is the best assumption here but normalizes and gives results that make sense here)\n",
        "# sigma_phi = 1 (assummes that a specialist that feeds on only one type of host will have a harder time invading than a generalist) (needs to be an integer)\n",
        "# sigma_kappa = just selected a value but plan on 1 - mean of the koppen climate matches\n",
        "# sigma_epsilon doesn't matter right now (we aren't using ecological disturbance this part of the equation drops out (i.e. changing this value doesn't afffect the simulation))\n",
        "# sigma_T - I still need to adjust this "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j9qNJz5tthVR",
        "colab": {}
      },
      "source": [
        "alpha = 0.2 #@param {type:\"number\"}\n",
        "beta = 0.2 #@param {type:\"number\"}\n",
        "mu = 0 #@param {type:\"number\"}\n",
        "lamda_c = 1 #@param {type:\"number\"}\n",
        "phi = 2 #@param {type:\"integer\"}\n",
        "sigma_epsilon = 0.5 #@param {type:\"number\"}\n",
        "sigma_h = 1 - 0.16 #@param {type:\"number\"}\n",
        "sigma_kappa = 1 - 0.3 #@param {type:\"number\"}\n",
        "sigma_phi =  1 #@param {type:\"integer\"}\n",
        "sigma_T = 10000 #@param {type:\"integer\"}\n",
        "start_year = 2000 #@param {type:\"integer\"}"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxFLsHuPRjaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_num = 23"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "M5FtYWb_BH6m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        },
        "outputId": "56acd772-a434-4de5-b319-6b9404d03a3f"
      },
      "source": [
        "# Runs the full model\n",
        "random_seed = None \n",
        "trades = trades\n",
        "distances = distances\n",
        "locations = countries\n",
        "prob = np.zeros(len(countries.index))\n",
        "pres_ts0 = [False] *len(prob)\n",
        "pres_ts0[china_index] = True \n",
        "pres_ts0[viet_nam_index] = True\n",
        "pres_ts0[india_index] = True\n",
        "locations[\"Presence\"] = pres_ts0\n",
        "#locations[\"Phytosanitary Capacity\"] = prob\n",
        "\n",
        "print('PARAMETER VALUES:')\n",
        "print(f'alpha: {alpha}\\tbeta: {beta}\\tmu: {mu}')\n",
        "print(f'sigma_h: {sigma_h}\\tsigma_kappa: {sigma_kappa}\\tsigma_T: {sigma_T}')\n",
        "\n",
        "comms = 'select_commodities'\n",
        "time_agg = 'monthly'\n",
        "\n",
        "print(f'Commodities: {comms} @ {time_agg}')\n",
        "print(f'GPD vals:\\n{gdp_dict}')\n",
        "\n",
        "e = pandemic2(\n",
        "    trades=trades,\n",
        "    distances=distances,\n",
        "    locations=locations,\n",
        "    alpha=alpha,\n",
        "    beta=beta,\n",
        "    mu=mu,\n",
        "    lamda_c=lamda_c,\n",
        "    phi=phi,\n",
        "    sigma_epsilon=sigma_epsilon,\n",
        "    sigma_h=sigma_h,\n",
        "    sigma_kappa=sigma_kappa,\n",
        "    sigma_phi=sigma_phi,\n",
        "    sigma_T=sigma_T,\n",
        "    start_year=start_year,\n",
        "    random_seed=random_seed\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PARAMETER VALUES:\n",
            "alpha: 0.2\tbeta: 0.2\tmu: 0\n",
            "sigma_h: 0.84\tsigma_kappa: 0.7\tsigma_T: 10000\n",
            "Commodities: select_commodities @ monthly\n",
            "GPD vals:\n",
            "{'low': 0.25, 'mid': 0.7, 'high': 0.9, nan: 0}\n",
            "TIME STEP:  200001\n",
            "TIME STEP:  200002\n",
            "TIME STEP:  200003\n",
            "TIME STEP:  200004\n",
            "TIME STEP:  200005\n",
            "TIME STEP:  200006\n",
            "TIME STEP:  200007\n",
            "TIME STEP:  200008\n",
            "TIME STEP:  200009\n",
            "TIME STEP:  200010\n",
            "TIME STEP:  200011\n",
            "TIME STEP:  200012\n",
            "TIME STEP:  200101\n",
            "TIME STEP:  200102\n",
            "TIME STEP:  200103\n",
            "TIME STEP:  200104\n",
            "TIME STEP:  200105\n",
            "TIME STEP:  200106\n",
            "TIME STEP:  200107\n",
            "TIME STEP:  200108\n",
            "TIME STEP:  200109\n",
            "TIME STEP:  200110\n",
            "TIME STEP:  200111\n",
            "TIME STEP:  200112\n",
            "TIME STEP:  200201\n",
            "TIME STEP:  200202\n",
            "TIME STEP:  200203\n",
            "TIME STEP:  200204\n",
            "TIME STEP:  200205\n",
            "TIME STEP:  200206\n",
            "TIME STEP:  200207\n",
            "TIME STEP:  200208\n",
            "TIME STEP:  200209\n",
            "TIME STEP:  200210\n",
            "TIME STEP:  200211\n",
            "TIME STEP:  200212\n",
            "TIME STEP:  200301\n",
            "TIME STEP:  200302\n",
            "TIME STEP:  200303\n",
            "TIME STEP:  200304\n",
            "TIME STEP:  200305\n",
            "TIME STEP:  200306\n",
            "TIME STEP:  200307\n",
            "TIME STEP:  200308\n",
            "TIME STEP:  200309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M67qQ8yfezAA"
      },
      "source": [
        "# **View and Save Output**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U2lDHwirfmeY",
        "colab": {}
      },
      "source": [
        "#Save model output objects\n",
        "check = e[0] \n",
        "prob_entry = e[1]\n",
        "prob_est = e[2] \n",
        "prob_intro = e[3]\n",
        "origin_dst = e[4] \n",
        "country_intro = e[5]\n",
        "date_list_out = e[6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEcsceZ-RjbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "arr_dict = {'prob_entry': 'probability_of_entry',\n",
        "           'prob_intro': 'probability_of_introduction',\n",
        "           'prob_est': 'probability_of_establishment',\n",
        "           'country_introduction': 'country_introduction'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlwGT_hKRjbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outpath = f'{data_dir}/slf_model/outputs/run{run_num}/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0SrD2995mgFT",
        "colab": {}
      },
      "source": [
        "def create_model_dirs(run_num, outpath, output_dict):\n",
        "    os.makedirs(outpath, exist_ok = True)\n",
        "    \n",
        "    for key in output_dict.keys():\n",
        "        os.makedirs(outpath + key, exist_ok = True)\n",
        "        print(outpath + key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huMWAH9vRjbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_model_dirs(run_num = run_num,\n",
        "                  outpath = outpath,\n",
        "                  output_dict = arr_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT3-XS1PDfdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_model_metadata(outpath, run_num, native_countries_list,\n",
        "                            comms, time_agg, gdp_dict, main_model_output, \n",
        "                            select_origin_dst):\n",
        "    \n",
        "    final_presence_col = sorted(\n",
        "        [c for c in gdf if c.startswith('Presence')]\n",
        "        )[-1]\n",
        "\n",
        "    with open(f'{outpath}run{run_num}_meta.txt', 'w') as file:\n",
        "        file.write(f'PARAMETER VALS:\\talpha: {alpha}' \\\n",
        "                   f'\\n\\tbeta: {beta}\\n\\tmu: {mu}' \\\n",
        "                   f'\\tsigma_h: {sigma_h}\\n\\tsigma_kappa: {sigma_kappa}\\n\\t' \\\n",
        "                   f'sigma_T: {sigma_T}\\n\\n')\n",
        "        file.write(f'NATIVE COUNTRIES AT T0:\\n\\t{native_countries_list}\\n\\n')\n",
        "        file.write(f'COMMODITIES: {comms} @ {time_agg}\\n\\n')\n",
        "        file.write('PHYTOSANITARY CAPACITY:\\n\\tDynamic by Year' \\\n",
        "                   '\\n\\tAggregated by equal intervals (i.e., \"Length\")\\n')\n",
        "        file.write(f'\\tGPD vals:{gdp_dict}\\n\\n')\n",
        "        file.write('COUNTRY INTRODUCTIONS:')\n",
        "        file.write(f'\\nTotal Number of Countries: ' \\\n",
        "                   f'{main_model_output[final_presence_col].value_counts()[1]}')\n",
        "        file.write(f'\\n{select_origin_dst.to_string()}')\n",
        "        file.close()\n",
        "        print(f'saving: {outpath}run{run_num}_meta.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr7iXcnrRjb9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "select_origin_dst = (origin_dst[origin_dst['Destination']\n",
        "                                .isin(known_introductions_list)])\n",
        "generate_model_metadata(outpath = outpath,\n",
        "                        run_num = run_num,\n",
        "                        native_countries_list = native_countries_list,\n",
        "                        comms = comms, \n",
        "                        time_agg = time_agg,\n",
        "                        gdp_dict = gdp_dict, \n",
        "                        main_model_output = e[0],\n",
        "                        select_origin_dst = select_origin_dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE6kkaVkRjcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_monthly_model_output(\n",
        "    model_output_object, \n",
        "    columns_to_drop, \n",
        "    outpath, \n",
        "    run_num\n",
        "    ):\n",
        "    check = model_output_object[0] #locations\n",
        "    prob_entry = model_output_object[1]\n",
        "    prob_est = model_output_object[2] \n",
        "    prob_intro = model_output_object[3]\n",
        "    origin_dst = model_output_object[4] \n",
        "    country_intro = model_output_object[5]\n",
        "    date_list_out = model_output_object[6]\n",
        "    \n",
        "    out_df = check.drop(columns_to_drop, axis=1)\n",
        "    out_df[\"geometry\"] = [MultiPolygon([feature]) if type(feature) == Polygon \n",
        "                          else feature for feature in out_df[\"geometry\"]]\n",
        "    out_df.to_file(outpath + f'pandemic_output.geojson', driver='GeoJSON')\n",
        "\n",
        "    origin_dst.to_csv(outpath + f'origin_destination.csv')\n",
        "    \n",
        "    for i in range(0, len(date_list_out)):\n",
        "        ts = date_list_out[i]\n",
        "        \n",
        "        pro_entry_pd = pd.DataFrame(prob_entry[i])\n",
        "        pro_entry_pd.columns = traded.columns\n",
        "        pro_entry_pd.index = traded.index\n",
        "        pro_entry_pd.to_csv(outpath \n",
        "                            + f\"prob_entry/probability_of_entry_{str(ts)}.csv\", \n",
        "                            float_format='%.2f', \n",
        "                            na_rep=\"NAN!\")\n",
        "        \n",
        "        pro_intro_pd = pd.DataFrame(prob_intro[i])\n",
        "        pro_intro_pd.columns = traded.columns\n",
        "        pro_intro_pd.index = traded.index\n",
        "        pro_intro_pd.to_csv(outpath \n",
        "                            + f\"prob_intro/probability_of_introduction_{str(ts)}.csv\", \n",
        "                            float_format='%.2f', \n",
        "                            na_rep=\"NAN!\")\n",
        "        \n",
        "        pro_est_pd = pd.DataFrame(prob_est[i])\n",
        "        pro_est_pd.columns = traded.columns\n",
        "        pro_est_pd.index = traded.index\n",
        "        pro_est_pd.to_csv(outpath \n",
        "                          + f\"prob_est/probability_of_establishment_{str(ts)}.csv\", \n",
        "                          float_format='%.2f', \n",
        "                          na_rep=\"NAN!\")\n",
        "        \n",
        "        country_int_pd = pd.DataFrame(country_intro[i])\n",
        "        country_int_pd.columns = traded.columns\n",
        "        country_int_pd.index = traded.index\n",
        "        country_int_pd.to_csv(outpath \n",
        "                              + f\"country_introduction/country_introduction_{str(ts)}.csv\", \n",
        "                              float_format='%.2f', \n",
        "                              na_rep=\"NAN!\")\n",
        "    \n",
        "    return out_df, date_list_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pA4PNV3crGwN",
        "colab": {}
      },
      "source": [
        "columns_to_drop = [\n",
        "                   'AREA_x', \n",
        "                   'Af',\n",
        "                   'Am',\n",
        "                   'Aw',\n",
        "                   'BWh',\n",
        "                   'BWk',\n",
        "                   'BSh',\n",
        "                   'BSk',\n",
        "                   'Csa',\n",
        "                   'Csb',\n",
        "                   'Csc',\n",
        "                   'Cwa',\n",
        "                   'Cwb',\n",
        "                   'Cwc',\n",
        "                   'Cfa',\n",
        "                   'Cfb',\n",
        "                   'Cfc',\n",
        "                   'Dsa',\n",
        "                   'Dsb',\n",
        "                   'Dsc',\n",
        "                   'Dsd',\n",
        "                   'Dwa',\n",
        "                   'Dwb',\n",
        "                   'Dwc',\n",
        "                   'Dwd',\n",
        "                   'Dfa',\n",
        "                   'Dfb',\n",
        "                   'Dfc',\n",
        "                   'Dfd',\n",
        "                   'ET',\n",
        "                   'EF',\n",
        "                   'NAME_y','Phytosanitary Capacity 2000',\n",
        "                   'Phytosanitary Capacity 2001',\n",
        "                   'Phytosanitary Capacity 2002',\n",
        "                   'Phytosanitary Capacity 2003',\n",
        "                   'Phytosanitary Capacity 2004',\n",
        "                   'Phytosanitary Capacity 2005',\n",
        "                   'Phytosanitary Capacity 2006',\n",
        "                   'Phytosanitary Capacity 2007',\n",
        "                   'Phytosanitary Capacity 2008',\n",
        "                   'Phytosanitary Capacity 2009',\n",
        "                   'Phytosanitary Capacity 2010',\n",
        "                   'Phytosanitary Capacity 2011',\n",
        "                   'Phytosanitary Capacity 2012',\n",
        "                   'Phytosanitary Capacity 2013',\n",
        "                   'Phytosanitary Capacity 2014',\n",
        "                   'Phytosanitary Capacity 2015',\n",
        "                   'Phytosanitary Capacity 2016',\n",
        "                   'Phytosanitary Capacity 2017',\n",
        "                   'Phytosanitary Capacity 2018',\n",
        "                   'Phytosanitary Capacity 2019',\n",
        "                   'Presence',\n",
        "                   'Probability of introduction',\n",
        "                   'pc_mode'\n",
        "                   ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atf4iqj4RjcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_out_df, date_list_out = save_monthly_model_output(model_output_object = e,\n",
        "                                   columns_to_drop = columns_to_drop,\n",
        "                                   outpath = outpath, \n",
        "                                   run_num = run_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc7nvATg7B_f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cumulative_prob(row, column_list):\n",
        "   non_neg = []\n",
        "   for i in range(0, len(column_list)):\n",
        "     if row[column_list[i]] > 0.:\n",
        "       non_neg.append(row[column_list[i]])\n",
        "   sub_list = list(map(lambda x: 1 - x, non_neg))\n",
        "   prod_out = np.prod(sub_list)\n",
        "   final_prob = 1 - prod_out\n",
        "   return final_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRWl1jd18Uhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_feature_cols(geojson_obj, feature_chars):\n",
        "    feature_cols = [c for c in geojson_obj.columns if \n",
        "                    c.startswith(feature_chars)]\n",
        "    feature_cols_monthly = [c for c in feature_cols if \n",
        "                            len(c.split(' ')[-1]) > 5]\n",
        "    feature_cols_annual = [c for c in feature_cols if \n",
        "                           c not in feature_cols_monthly]\n",
        "    \n",
        "    return feature_cols, feature_cols_monthly, feature_cols_annual   \n",
        "\n",
        "def create_feature_dict(geojson_obj, column_list, chars_to_strip):\n",
        "    d = geojson_obj[column_list].to_dict('index')\n",
        "    for key in d.keys():\n",
        "        d[key] = {k.strip(chars_to_strip): v for k, v in d[key].items()}\n",
        "    \n",
        "    return d\n",
        "\n",
        "def add_dict_to_geojson(geojson_obj, new_col_name, dictionary_obj):\n",
        "    geojson_obj[new_col_name] = geojson_obj.index.map(dictionary_obj)\n",
        "    \n",
        "    return geojson_obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3VLwlnSRjcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def aggregate_monthly_output_to_annual(formatted_geojson):\n",
        "  presence_cols = [c for c in formatted_geojson.columns \n",
        "                   if c.startswith('Presence')]\n",
        "  prob_intro_cols = [c for c in formatted_geojson.columns \n",
        "                     if c.startswith('Probability of introduction')]\n",
        "  annual_ts_list = sorted(set([y.split(' ')[-1][:4] \n",
        "                               for y in prob_intro_cols]))\n",
        "  for year in annual_ts_list:\n",
        "    prob_cols = [c for c in prob_intro_cols if str(year) in c]\n",
        "    formatted_geojson[f'Agg Prob Intro {year}'] = (\n",
        "        formatted_geojson.apply(lambda row: \n",
        "                                cumulative_prob(row = row,\n",
        "                                                column_list = prob_cols),\n",
        "                                axis=1)\n",
        "    )\n",
        "    formatted_geojson[f'Presence {year}'] = formatted_geojson[f'Presence {year}12']\n",
        "    \n",
        "  formatted_geojson.to_file(outpath + f'pandemic_output_aggregated.geojson', \n",
        "                            driver='GeoJSON')\n",
        "  out_csv = pd.DataFrame(formatted_geojson)\n",
        "  out_csv.drop(['geometry'], axis=1, inplace=True)\n",
        "  out_csv.to_csv(outpath + f'pandemic_output_aggregated.csv', \n",
        "                float_format='%.2f', \n",
        "                na_rep=\"NAN!\")\n",
        "  presence_cols_monthly =  [c for c in presence_cols \n",
        "                            if len(c.split(' ')[-1]) > 5]\n",
        "  presence_cols_annual = [c for c in presence_cols \n",
        "                          if c not in presence_cols_monthly]\n",
        "  agg_prob_cols_annual = [c for c in formatted_geojson.columns \n",
        "                          if c.startswith('Agg')]\n",
        "  \n",
        "  presence_d = create_feature_dict(geojson_obj = formatted_geojson,\n",
        "                                   column_list = presence_cols_annual,\n",
        "                                   chars_to_strip = 'Presence ')\n",
        "  agg_prob_d = create_feature_dict(geojson_obj = formatted_geojson,\n",
        "                                   column_list = agg_prob_cols_annual,\n",
        "                                   chars_to_strip = 'Agg Prob Intro ')\n",
        "  new_gdf = add_dict_to_geojson(geojson_obj = formatted_geojson,\n",
        "                              new_col_name = 'Presence',\n",
        "                              dictionary_obj = presence_d)\n",
        "  new_gdf = add_dict_to_geojson(geojson_obj = new_gdf,\n",
        "                              new_col_name = 'Agg Prob Intro',\n",
        "                              dictionary_obj = agg_prob_d)\n",
        "  cols_to_drop = [c for c in new_gdf.columns if\n",
        "                  c in presence_cols_monthly or\n",
        "                  c.startswith('Probability')]\n",
        "\n",
        "  sm_gdf = new_gdf.drop(cols_to_drop, axis=1)\n",
        "  sm_gdf.to_file(outpath + f'pandemic_output_aggregated_filtered.geojson', \n",
        "                  driver='GeoJSON')\n",
        "  sm_csv = pd. pd.DataFrame(sm_gdf)\n",
        "  sm_csv.drop(['geometry', 'Agg Prob Intro', 'Presence'], axis=1, inplace=True)\n",
        "  sm_csv.to_csv(outpath + f'pandemic_output_aggregated_select.csv', \n",
        "                float_format='%.2f', \n",
        "                na_rep=\"NAN!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqVloWzCRjcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aggregate_monthly_output_to_annual(formatted_geojson = full_out_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4Y8Qvq6Rjc0",
        "colab_type": "text"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x7nDrCi2B20-",
        "colab": {}
      },
      "source": [
        "# check = e[0]\n",
        "# # check_centroids = check.centroid\n",
        "# check['Presence T25'].values.sum()\n",
        "\n",
        "\n",
        "# check['Probability of introduction T2'].values\n",
        "# np.zeros(shape=len(locations))\n",
        "# check.columns\n",
        "\n",
        "# check.plot(column='Presence_T')\n",
        "# check.plot(column='Probability of introduction T1')\n",
        "# col_name = 'Presence T' +str(i)\n",
        "\n",
        "# for i in range(26):\n",
        "#   col_name = 'Presence ' +str(i + start_year)\n",
        "#   col_name2 = 'Probability of introduction ' +str(i + start_year)\n",
        "#   check_centroids = check.loc[check[col_name]].centroid\n",
        "#   fig, ax = plt.subplots(figsize=(28,14))\n",
        "#   check.plot(ax=ax, column=col_name2, legend = True, figsize=(30, 15))\n",
        "#   check_centroids.plot(ax = ax, color = 'red')\n",
        "#   plt.title('Citrust Pest presence in ' + str(i + start_year), color='white')\n",
        "#   # plt.legend()\n",
        "#   plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCcbTRGeRjdD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test = geopandas.read_file(f'{data_dir}/slf_model/outputs/annual/all_commodities/geojson/pandemic_output_test1.geojson',\n",
        "#                           driver='GeoJSON')\n",
        "# test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gumy7aGCf7xU",
        "colab": {}
      },
      "source": [
        "## write geojson outputs for MapBox example\n",
        "# outpath = '/content/drive/Shared drives/APHIS  Projects/Pandemic/Data/slf_model/outputs/'\n",
        "## write out csv for origin destination year pairs.\n",
        "# test.to_csv(outpath + \"pandemic_output_origin_destination.csv\")\n",
        "# check = e[0]\n",
        "# check.drop(columns=['Host Percent Area T0',\n",
        "#        'Host Percent Area T1', 'Host Percent Area T2', 'Host Percent Area T3',\n",
        "#        'Host Percent Area T4', 'Host Percent Area T5', 'Host Percent Area T6',\n",
        "#        'Host Percent Area T7', 'Host Percent Area T8', 'Host Percent Area T9',\n",
        "#        'Host Percent Area T10', 'Host Percent Area T11',\n",
        "#        'Host Percent Area T12', 'Host Percent Area T13',\n",
        "#        'Host Percent Area T14', 'Host Percent Area T15',\n",
        "#        'Host Percent Area T16', 'Host Percent Area T17',\n",
        "#        'Host Percent Area T18', 'Host Percent Area T19',\n",
        "#        'Host Percent Area T20', 'Host Percent Area T21',\n",
        "#        'Host Percent Area T22', 'Host Percent Area T23',\n",
        "#        'Host Percent Area T24', 'Host Percent Area T25',\n",
        "#        'Presence', 'phytosanitary_compliance', 'Probability of introduction',\n",
        "#        'Host Percent Area', 'AREA', 'Af', 'Am',\t'Aw',\t'BWh', 'BWk', 'BSh', 'BSk',\n",
        "#        'Csa',\t'Csb', 'Csc', 'Cwa', 'Cwb', 'Cwc', 'Cfa',\t'Cfb', 'Cfc',\t'Dsa',\n",
        "#        'Dsb',\t'Dsc', 'Dsd',\t'Dwa', 'Dwb',\t'Dwc', 'Dwd',\t'Dfa', 'Dfb',\t'Dfc',\n",
        "#        'Dfd',\t'ET', 'EF'], inplace = True)\n",
        "# check[['geometry', 'Probability of introduction T1', 'Presence T1']]\n",
        "# check\n",
        "# centroids = check.centroid.geometry\n",
        "# # centroids = centroids.set_crs(epsg=4326)\n",
        "# # centroids = centroids.to_crs(epsg=3857)\n",
        "# # centroids = centroids.set_crs(epsg=3857)\n",
        "# centroids = geopandas.GeoDataFrame(centroids)\n",
        "# centroids = centroids.rename(columns={0: 'geometry'}).set_geometry('geometry')\n",
        "# centroids[\"NAME\"] = check[\"NAME\"]\n",
        "# centroids[\"title\"] = \"Spotted Lanternfly\"\n",
        "# centroids[\"icon\"] = \"SLF\"\n",
        "\n",
        "# # type(check)\n",
        "\n",
        "# ## write out yearly geojson\n",
        "# for i in range(19):\n",
        "#   col_name = 'Presence ' +str(i + start_year)\n",
        "#   centroids[col_name] = check[col_name]\n",
        "#   # col_name2 = 'Probability of introduction ' +str(i)\n",
        "#   # c = check.loc[:,['geometry', col_name, col_name2]]\n",
        "#   # cc = check.loc[check[col_name]].centroid\n",
        "#   # c.to_file(outpath + \"pandemic_output\" + str(i + 1993) + \".geojson\", driver='GeoJSON')\n",
        "\n",
        "\n",
        "# ## write out yearly geojsons with both polygons and points in case we want to display the presence as an icon\n",
        "# # for i in range(26):\n",
        "# #   col_name = 'Presence ' +str(i + start_year)\n",
        "# #   col_name2 = 'Probability of introduction ' +str(i + start_year)\n",
        "# #   c = check.loc[:,['geometry', col_name2, 'NAME']]\n",
        "# #   cc = check.centroid\n",
        "# #   c.columns = ['geometry', 'Probability of introduction', 'NAME']\n",
        "# #   cc['NAME'] = c['NAME'].values\n",
        "# #   # cc.columns = ['geometry', 'Presence']\n",
        "# #   c['Year'] = i + start_year\n",
        "# #   # cc['Year'] = i + start_year\n",
        "# #   if i == 0:\n",
        "# #     pres_output = cc\n",
        "# #     prob_output = c\n",
        "# #   else:\n",
        "# #     pres_output = pres_output.append(cc, ignore_index=True)\n",
        "# #     prob_output = prob_output.append(c, ignore_index=True)\n",
        "\n",
        "#   # c.to_file(outpath + \"pandemic_output_prob\" + str(i + 1993) + \".geojson\", driver='GeoJSON')\n",
        "#   # cc.to_file(outpath + \"pandemic_output_pres\" + str(i + 1993) + \".geojson\", driver='GeoJSON')\n",
        "\n",
        "# centroids\n",
        "# # check.crs\n",
        "\n",
        "# centroids.to_file(outpath + \"presence_pandemic.geojson\", driver='GeoJSON')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bn-bZ0iBkd62",
        "colab": {}
      },
      "source": [
        "# prob_output\n",
        "# import plotly.express as px\n",
        "# fig = px.choropleth(prob_output, locations=\"NAME\", color=\"Probability of introduction\", hover_name=\"NAME\", animation_frame=\"Year\", range_color=[0,1])\n",
        "# fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4vuTZE-twwQu",
        "colab": {}
      },
      "source": [
        "# import plotly.express as px\n",
        "# df = px.data.gapminder()\n",
        "# fig = px.choropleth(df, locations=\"iso_alpha\", color=\"lifeExp\", hover_name=\"country\", animation_frame=\"year\", range_color=[20,80])\n",
        "# # fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}