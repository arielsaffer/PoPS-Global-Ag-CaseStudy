{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brier score\n",
    "Testing out a new metric of forecast skill with a binary outocme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import math\n",
    "# import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_root = \"Q:\"\n",
    "data_path = r\"\\Shared drives\\Pandemic Data\"\n",
    "model_name = \"slf_model\"\n",
    "run_name = \"slf_grid_broad\"\n",
    "commodity = \"6802-6802\"\n",
    "years_before_firstRecord = 4\n",
    "native_countries_list = [\"China\",\"Viet Nam\"]\n",
    "\n",
    "data_dir = f\"{google_root}{data_path}\\{model_name}\"\n",
    "\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dir = f\"{data_dir}/outputs/summary_stats/{run_name}\"\n",
    "# input_dir = \"inputs\"\n",
    "input_dir = f\"{data_dir}/inputs/noTWN\"\n",
    "out_dir = f\"{data_dir}/outputs/slf_origin/{run_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv(\n",
    "    input_dir + \"/first_records_validation.csv\",\n",
    "    header=0,\n",
    "    index_col=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_samp = glob.glob(f\"{out_dir}/*{commodity}*\")\n",
    "run_outputs = glob.glob(f\"{sample}/run*/pandemic_output_aggregated.csv\")\n",
    "\n",
    "def compute_brier_score(run_outputs, validation_df, native_countries_list, years_before_firstRecord):\n",
    "\n",
    "    model_output = pd.read_csv(run_outputs[0])\n",
    "    \n",
    "    presence_cols = [\n",
    "    c\n",
    "    for c in model_output.columns\n",
    "    if c.startswith(\"Presence\") and len(c.split(\" \")[-1]) == 4]\n",
    "\n",
    "    years = [\n",
    "    c.split(\" \")[-1]    \n",
    "    for c in presence_cols\n",
    "    ]\n",
    "    \n",
    "    # Remove native countries\n",
    "    model_output.drop(model_output.loc[model_output['NAME'].isin(native_countries_list)].index, inplace=True)\n",
    "    validation = model_output.merge(validation_df, how=\"left\", on=\"ISO3\")[['ISO3','ObsFirstIntro']]\n",
    "\n",
    "    for year in years:\n",
    "        validation[year] = 0\n",
    "        validation.loc[validation['ObsFirstIntro'] <= int(year),year] = 1\n",
    "\n",
    "    validation_w_lag = validation.copy() \n",
    "    for year in years:\n",
    "        validation_w_lag.loc[validation_w_lag['ObsFirstIntro'] <= int(year) + years_before_firstRecord,year] = 1\n",
    "\n",
    "    validation.drop(columns=[\"ISO3\",\"ObsFirstIntro\"], inplace=True)\n",
    "    validation_w_lag.drop(columns=[\"ISO3\",\"ObsFirstIntro\"], inplace=True)\n",
    "\n",
    "    total_intros = model_output[presence_cols].values\n",
    "    \n",
    "    for run in run_outputs:\n",
    "        model_output = pd.read_csv(run)\n",
    "        model_output.drop(model_output.loc[model_output['NAME'].isin(native_countries_list)].index, inplace=True)\n",
    "        total_intros = np.dstack((total_intros, model_output[presence_cols].values))\n",
    "    \n",
    "    mean_intros = np.mean(total_intros, axis=2)\n",
    "\n",
    "    # For each value that is in the window period, pick the score that does better (presence or absence)\n",
    "    brier_scores = np.minimum((mean_intros - validation.values)**2, (mean_intros - validation_w_lag.values)**2)\n",
    "\n",
    "    brier_score = np.mean(brier_scores)\n",
    "\n",
    "    return brier_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_samp = glob.glob(f\"{out_dir}/*{commodity}*\")\n",
    "run_outputs = glob.glob(f\"{param_samp[1]}/run*/pandemic_output_aggregated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0031904446576663014"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_brier_score(run_outputs, validation_df, native_countries_list, years_before_firstRecord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remaking the summary stats by sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "coi = \"USA\"\n",
    "\n",
    "validation_df = pd.read_csv(\n",
    "        input_dir + \"/first_records_validation.csv\", header=0, index_col=0,\n",
    "    )\n",
    "\n",
    "# Set up probability by year dictionary keys (column names)\n",
    "sim_years =[2014, 2020]\n",
    "year_probs_dict_keys = []\n",
    "for year in sim_years:\n",
    "    year_probs_dict_keys.append(f\"prob_by_{year}_{coi}\")\n",
    "\n",
    "# Set up difference by recorded country dictionary keys (column names)\n",
    "countries_dict_keys = []\n",
    "for ISO3 in validation_df.index:\n",
    "    countries_dict_keys.append(f\"diff_obs_pred_metric_{ISO3}\")\n",
    "\n",
    "data = pd.read_csv(\n",
    "        r\"C:\\\\Users\\\\asaffer\\\\OneDrive - North Carolina State University\\Documents\\\\MobaXterm\\slf_model\\slf_origin\\outputs\\summary_stats\\slf_grid_broad\" + \"/summary_stats_wPrecisionRecallF1FBetaAggProb.csv\", header=0, index_col=0, usecols=list(range(0,21))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "\n",
    "def avg_std(x):\n",
    "    \"\"\"\n",
    "    Compute average standard deviation when aggregating across runs\n",
    "    of a parameter sample\n",
    "    \"\"\"\n",
    "    return math.sqrt(sum(x ** 2) / len(x))\n",
    "\n",
    "\n",
    "def mape(x):\n",
    "    return (1 / len(x)) * sum(abs(x / 3))\n",
    "\n",
    "\n",
    "def fbeta(precision, recall, weight):\n",
    "    if (precision != 0) and (recall != 0):\n",
    "        return ((1 + (weight ** 2)) * precision * recall) / (\n",
    "            (weight ** 2) * precision + recall\n",
    "        )\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def f1(precision, recall):\n",
    "    if (precision != 0) and (recall != 0):\n",
    "        return (2 * precision * recall) / (precision + recall)\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dict = {\n",
    "        \"start\": [\"max\"],\n",
    "        \"alpha\": [\"max\"],\n",
    "        \"lamda\": [\"max\"],\n",
    "        \"run_num\": [\"max\"],\n",
    "        \"total_countries_intros_predicted\": [\"mean\", \"std\"],\n",
    "        \"diff_total_countries\": [\"mean\", \"std\"],\n",
    "        \"diff_total_countries_sqrd\": [mse],\n",
    "        \"count_known_countries_time_window\": [\"mean\", \"std\"],\n",
    "        \"diff_obs_pred_metric_mean\": [\"mean\"],\n",
    "        \"diff_obs_pred_metric_stdev\": [avg_std],\n",
    "        \"count_known_countries_time_window_recall\": [\"mean\"],\n",
    "        \"count_known_countries_time_window_precision\": [\"mean\"],\n",
    "        \"count_known_countries_time_window_f1\": [\"mean\"],\n",
    "        \"count_known_countries_time_window_fbeta\": [\"mean\"],\n",
    "    }\n",
    "prob_agg_dict = dict(\n",
    "    zip(year_probs_dict_keys, [\"mean\" for i in range(len(year_probs_dict_keys))])\n",
    ")\n",
    "countries_agg_dict = dict(\n",
    "    zip(\n",
    "        countries_dict_keys,\n",
    "        [[\"mean\", \"std\"] for i in range(len(countries_dict_keys))],\n",
    "    )\n",
    ")\n",
    "\n",
    "agg_dict = {**agg_dict, **prob_agg_dict, **countries_agg_dict}\n",
    "\n",
    "agg_df = data.groupby(\"sample\").agg(agg_dict)\n",
    "\n",
    "agg_df.columns = [\"_\".join(x) for x in agg_df.columns.values]\n",
    "# agg_df.to_csv(summary_stat_path + \"/summary_stats_bySample.csv\")\n",
    "\n",
    "agg_df.to_csv(r\"C:\\Users\\asaffer\\OneDrive - North Carolina State University\\Documents\\MobaXterm\\slf_model\\slf_origin\\outputs\\summary_stats\\slf_grid_broad\" + \"/summary_stats_bySample.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "948a6e006881c847639198d4e28507cd0955feff6e008072919ba7456f12f8bf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('Pandemic': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
